{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\t\"github.com/pa-m/sklearn/metrics\"\n",
    "\t    ms \"github.com/pa-m/sklearn/model_selection\"\n",
    "\t\t\"github.com/e-XpertSolutions/go-iforest/iforest\"\t\n",
    "\t\t\"bufio\"\n",
    "\t\t\"encoding/csv\"\n",
    "\t\t\"strconv\"\n",
    "\t\t\"github.com/janpfeifer/gonb/gonbui\"\n",
    "\t\t\"gonum.org/v1/plot/plotutil\"\n",
    "\t\t\"gonum.org/v1/plot\"\n",
    "\t\t\"gonum.org/v1/plot/plotter\"\n",
    "\t\t\"gonum.org/v1/plot/vg\"\n",
    "\t\t\"gonum.org/v1/plot/vg/draw\"\n",
    "\t\t\"os/exec\"\n",
    "\t\t\"github.com/janpfeifer/gonb/cache\"\n",
    "\t\t\"math\"\n",
    "\t\t\"math/rand\"\n",
    "\n",
    "\t)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "//load file Data and Return [][]float64 array\n",
    "func loadData(myfile string) [][]float64 {\n",
    "\n",
    "\tl:=false\n",
    "file, err := os.Open(myfile)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error opening file:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\n",
    "\treader := csv.NewReader(file)\n",
    "\trecords, err := reader.ReadAll()\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error reading CSV:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\t\n",
    "\tinputData := make([][]float64, len(records))\n",
    "\tfor i, row := range records {\n",
    "\n",
    "\t\tinputData[i] = make([]float64, len(row))\n",
    "\t\tfor j, value := range row {\n",
    "\t\t\tinputData[i][j], err = strconv.ParseFloat(value, 64)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tfmt.Printf(\"Error converting to float: line %d\",i)\n",
    "\t\t\t\tl=true\n",
    "\t\t\t\tbreak\t\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tif l == true{\n",
    "\t\t\tbreak\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn inputData\n",
    "}\n",
    "\n",
    "func LoadLabels(filePath string)[]int{\n",
    "\tfile, err := os.Open(filePath)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error opening file:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\n",
    "\tscanner := bufio.NewScanner(file)\n",
    "\t\n",
    "\tvar labels []int\n",
    "\n",
    "\tfor scanner.Scan() {\n",
    "\t\tlabel,err := strconv.Atoi(scanner.Text())\n",
    "\t\tif err != nil {\n",
    "\t\t\t// Handle the error if the conversion fails\n",
    "\t\t\tfmt.Println(\"Error:\", err)\n",
    "\t\t\treturn nil\n",
    "\t\t}\n",
    "\t\tlabels= append(labels,label)\n",
    "\t}\n",
    "\treturn labels\n",
    "}\n",
    "\n",
    "//Convert labels to float for F1 and Accuracy Score metrics\n",
    "func ConvertToFloat(Labels_Pred []int , labels_Tru []int)([]float64 ,[]float64){\n",
    "\n",
    "\tlength :=len(Labels_Pred)\n",
    "\tlabelsPred_float := make([]float64, length)\n",
    "\tlabelsTru_float := make([]float64, length)\n",
    "\n",
    "\tfor i:=0; i<length; i++ {\n",
    "\t\t\n",
    "\t\tlabelsPred_float[i] = float64(Labels_Pred[i])\n",
    "\t\tlabelsTru_float[i] = float64(labels_Tru[i])\n",
    "\t\t\n",
    "\t}\n",
    "\treturn labelsPred_float,labelsTru_float\n",
    "\n",
    "}\n",
    "\n",
    "func F1Score(labelsPred []int, labelsTru []int) float64{\n",
    "\n",
    "\tpred,tru := ConvertToFloat(labelsPred,labelsTru)\n",
    "\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\tvar sampleWeight []float64\n",
    "\t/* fmt.Printf(\"F1 macro %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"macro\", sampleWeight))\n",
    "\tfmt.Printf(\"F1 micro %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"micro\", sampleWeight))\n",
    "\tfmt.Printf(\"F1 weighted %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"weighted\", sampleWeight)) */\n",
    "\treturn metrics.F1Score(Ytrue, Ypred, \"macro\", sampleWeight)\n",
    "\n",
    "}\n",
    "\n",
    "func AccuracyScore(labelsPred []int, labelsTru []int)float64{\n",
    "\n",
    "\tpred,tru := ConvertToFloat(labelsPred,labelsTru)\n",
    "\n",
    "\tvar nilDense *mat.Dense\n",
    "\tnormalize, sampleWeight := true, nilDense\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\treturn metrics.AccuracyScore(Ytrue, Ypred, normalize, sampleWeight)\n",
    "\n",
    "}\n",
    "\n",
    "// call command line executable\n",
    "func prepareDataset(dataset string){\n",
    "\tcmd :=exec.Command(\"./extract_splitDataset.sh\", dataset)\n",
    "\tcmd.Run()\n",
    "}\n",
    "\n",
    "func Mean(array []float64)float64{\n",
    "\tsum := 0.0\n",
    "    for _, num := range array {\n",
    "        sum += num\n",
    "    }\n",
    "\n",
    "    // Calculate the mean\n",
    "    mean := sum / float64(len(array))\n",
    "\treturn mean\n",
    "}\n",
    "\n",
    "func outlierRatio(lab []int) float64{\n",
    "\tcount :=0 \n",
    "\tfor _,v := range lab{\n",
    "\t\tif v == 1{\n",
    "\t\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\tanomaly := float64(count)/float64(len(lab))\n",
    "\treturn anomaly\n",
    "}\n",
    "\n",
    "func findMaxIndex(arr []float64)int{\n",
    "\n",
    "\tmaxIndex := 0 \n",
    "\n",
    "    for i := 1; i < len(arr); i++ {\n",
    "     \n",
    "        if arr[i] > arr[maxIndex] {\n",
    "            maxIndex = i\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return maxIndex \n",
    "}\n",
    "\n",
    "\n",
    "func BuildLabelsArray(lendata int, lenzerodata int)[]int{\n",
    "\n",
    "\n",
    "labeldata := make([]int, lendata)\n",
    "\t\t\tfor i:=0; i<lendata; i++{\n",
    "\t\t\t\tif i < lenzerodata{\n",
    "\t\t\t\tlabeldata[i] = 0\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\tlabeldata[i] = 1\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\treturn labeldata\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Isolation Forest algorithm\n",
    "\n",
    "func isoForestTrain_Test(training_data [][]float64 ,testing_data [][]float64 , treesNumber int, subsampleSize int, outliers float64) *iforest.Forest{\n",
    "//model initialization\n",
    "forest := iforest.NewForest(treesNumber, subsampleSize, outliers)\n",
    "\n",
    "//training stage - creating trees\n",
    "forest.Train(training_data)\n",
    "\n",
    "//testing stage - finding anomalies \n",
    "forest.Test(testing_data)\n",
    "\n",
    "//threshold := forest.AnomalyBound\n",
    "//labels := forest.Labels\n",
    "\n",
    "//fmt.Println(\"threshold is\",threshold)\n",
    "\n",
    "return forest;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Split struct{\n",
    "\tTrainData [][] float64\n",
    "\tValidateData [][] float64\n",
    "\tLabelData []int\n",
    "\t//trainLabelData []int for unit testing\n",
    "\t}\n",
    "\n",
    "func SplitDataset (dataset [][]float64, labels[]int, splitRatio float64)(map[int][][]float64,map[int][][]float64,float64){\n",
    "\n",
    "\tmyMap := make(map[int][][]float64)\n",
    "\tTrainingIndex_Data := make(map[int][][]float64)\n",
    "\tTestingIndex_Data := make(map[int][][]float64)\n",
    "\tcount:=0\n",
    "\tfor i,instance:= range dataset{\n",
    "\t\tif labels[i] == 0{\n",
    "\t\tmyMap[0] = append(myMap[0], instance)\n",
    "\t\t}else{\n",
    "\t\tmyMap[1] = append(myMap[1], instance)\n",
    "\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\tShuffleUnit(myMap)\n",
    "\tsplit0:= int(math.Round(splitRatio * float64(len(myMap[0]))))\n",
    "\tsplit1:= int(math.Round(splitRatio * float64(len(myMap[1]))))\n",
    "\n",
    "\tTrainingIndex_Data[0] = myMap[0][:split0]\n",
    "\tTrainingIndex_Data[1] = myMap[1][:split1]\n",
    "\tTestingIndex_Data[0] = myMap[0][split0:]\n",
    "\tTestingIndex_Data[1] = myMap[1][split1:] \n",
    "\n",
    "\tanomaly := float64(count)/float64(len(labels))\n",
    "\treturn  TrainingIndex_Data, TestingIndex_Data, anomaly\n",
    "}\n",
    "\n",
    "func Shuffle(testing_set [][]float64, training_set [][]float64, label_set []int){\n",
    "\n",
    "\trand.Shuffle(len(training_set), func(i, j int) {\n",
    "\t\ttraining_set[i], training_set[j] = training_set[j], training_set[i]\n",
    "\t})\n",
    "\trand.Shuffle(len(testing_set), func(i, j int) {\n",
    "\t\ttesting_set[i], testing_set[j] = testing_set[j], testing_set[i]\n",
    "\t\tlabel_set [i], label_set[j] = label_set[j], label_set[i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func ShuffleUnit(data_label map[int][][]float64){\n",
    "\n",
    "\trand.Shuffle(len(data_label[0]), func(i, j int) {\n",
    "\t\tdata_label[0][i], data_label[0][j] = data_label[0][j], data_label[0][i]\n",
    "\t})\n",
    "\trand.Shuffle(len(data_label[1]), func(i, j int) {\n",
    "\t\tdata_label[1][i], data_label[1][j] = data_label[1][j], data_label[1][i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func StratifiedKFold(K int, data_label map[int][][]float64)(ch chan Split){\n",
    "\n",
    "\n",
    "\tfoldSizezeros:= int(math.Round(float64((len(data_label[0])/K))))\n",
    "\tfoldSizeones:= int(math.Round((float64(len(data_label[1])/K))))\n",
    "\n",
    "\tch = make(chan Split)\n",
    "\t\n",
    "\tgo func(){\n",
    "\t\t\n",
    "\t\tvar sp *Split\n",
    "\t\tfor i:=0; i<K; i++{\n",
    "\t\t\tstartIndex0 := i * foldSizezeros\n",
    "\t\t\tendIndex0 := (i + 1) * foldSizezeros\n",
    "\t\t\tstartIndex1 := i * foldSizeones\n",
    "\t\t\tendIndex1 := (i + 1) * foldSizeones\n",
    "\n",
    "\t\t\tif i == K-1 {\n",
    "\t\t\t\tendIndex0 = len(data_label[0])\n",
    "\t\t\t\tendIndex1 = len(data_label[1])\n",
    "\t\t\t}\n",
    "\t\t\ttrainData0 := make([][]float64, 0)\n",
    "\t\t\ttrainData1 := make([][]float64, 0)\n",
    "\n",
    "\t\t\t// Merge all data except the test data into the training data\n",
    "\t\t\ttrainData0 = append(trainData0, data_label[0][:startIndex0]...)\n",
    "\t\t\ttrainData0 = append(trainData0, data_label[0][endIndex0:]...)\n",
    "\t\t\ttrainData1 = append(trainData1, data_label[1][:startIndex1]...)\n",
    "\t\t\ttrainData1 = append(trainData1, data_label[1][endIndex1:]...)\n",
    "\t\t\t\n",
    "\t\t\ttrainData := Merge(trainData0,trainData1)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\ttestData0:=data_label[0][startIndex0:endIndex0]\n",
    "\t\t\ttestData1:=data_label[1][startIndex1:endIndex1]\n",
    "\t\t\t\n",
    "\t\t\ttestData := Merge(testData0, testData1)\n",
    "\n",
    "\t\t\ttestDatalen:= len(testData)\n",
    "\t\t\n",
    "\t\t    labeldata:= BuildLabelsArray(testDatalen,len(testData0))\n",
    "\t\t\t\n",
    "\t\t\tShuffle(testData,trainData,labeldata)\n",
    "\t\t\t\n",
    "\t\t\tsp = &Split{\n",
    "\t\t\t\tTrainData: trainData,\n",
    "\t\t\t\tValidateData:  testData,\n",
    "\t\t\t\tLabelData: labeldata,\n",
    "\t\t\t\t//trainLabelData: trainlabeldata,\n",
    "\t\t\t}\n",
    "\t\t\tch <- *sp\n",
    "\t\t}\n",
    "\t\tclose(ch)\t\n",
    "\t}()\n",
    "\treturn ch\n",
    "}\n",
    "\n",
    "func Merge(data1 [][]float64, data2 [][]float64)[][]float64{\n",
    "\n",
    "\tconcatenated:=make([][]float64, len(data1)+len(data2))\n",
    "\t\t\t\t\tcopy(concatenated, data1)\n",
    "    \t\t\t\tcopy(concatenated[len(data1):], data2)\n",
    "\treturn concatenated\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "type config struct{\n",
    "\ttreeNum int\n",
    "\tsubsamplesize int\n",
    "}\n",
    "\n",
    "func CrossValidation(data map[int][][]float64,treenummax int,subsamplmax int,anomaly float64) *config{\n",
    "\n",
    "\tmeanAccArr := make([]float64,0)\n",
    "\tconfigArr := make([]config,0)\n",
    "\n",
    "\tfor tr_n :=10 ;tr_n <=treenummax; tr_n+= 10{\n",
    "\t\tfor sss := 100; sss<=subsamplmax; sss+= 50{\n",
    "\t\t\tvar conf *config\n",
    "\t\t\tfmt.Println(\"Tree number = \",tr_n)\n",
    "\t\t\tfmt.Println(\"Subsamplingsize = \",sss)\n",
    "\t\t\tAcc_arr:=make([]float64,0)\n",
    "\t\t\t//F1_arr:=make([]float64,0)\n",
    "\t\t\tfor s := range StratifiedKFold(5,data){\n",
    "\t\t\t\t\tforest:=isoForestTrain_Test(s.TrainData, s.ValidateData,tr_n,sss,anomaly)\n",
    "\t\t\t\t\tAcc_arr = append(Acc_arr,AccuracyScore(forest.Labels,s.LabelData))\n",
    "\t\t\t\t\t//F1_arr = append(F1_arr,F1Score(forest.Labels,s.LabelData))\n",
    "\t\t\t\t}\n",
    "\t\t\t\t\t\n",
    "\t\t\tmean_accuracy:= Mean(Acc_arr)\n",
    "\t\t\tfmt.Println(\"Mean accuracy is \",mean_accuracy)\n",
    "\t\t    meanAccArr = append(meanAccArr,mean_accuracy)\n",
    "\n",
    "\t\t    conf = &config{\n",
    "\t\t\t\ttreeNum:tr_n,\n",
    "\t\t\t\tsubsamplesize:sss,\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tconfigArr = append(configArr,*conf)\n",
    "\t\t}\n",
    "\t}\n",
    "\tmaxIndex := findMaxIndex(meanAccArr)\n",
    "\tbestConfig := configArr[maxIndex]\n",
    "\treturn &bestConfig\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly ratio is:  0.07193103596551799\n",
      "Tree number =  10\n",
      "Subsamplingsize =  100\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "Mean accuracy is  0.924115625\n",
      "Tree number =  10\n",
      "Subsamplingsize =  150\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "Mean accuracy is  0.9161131250000001\n",
      "Tree number =  20\n",
      "Subsamplingsize =  100\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "8.364671030069179\n",
      "Mean accuracy is  0.9168731250000001\n",
      "Tree number =  20\n",
      "Subsamplingsize =  150\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "9.175657275024252\n",
      "Mean accuracy is  0.9195656249999999\n",
      "&{10 100}\n",
      "8.364671030069179\n",
      "Predict Accuracy is... 0.9101222753056882\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "data:=loadData(\"dataset.csv\")\n",
    "labels:=LoadLabels(\"labels.csv\")\n",
    "training_data , testing_data , anomaly :=  SplitDataset(data,labels,0.8)\n",
    "fmt.Println(float64(len(testing_data[0])/float64(len(testing_data[1])))\n",
    "fmt.Println(\"anomaly ratio is: \",anomaly)\n",
    "configuration := CrossValidation(training_data,20,150,anomaly) //returns the Best configuration {treeNum}{SubsamplingSize}\n",
    "fmt.Println(configuration)\n",
    "\n",
    "\n",
    "forestt := isoForestTrain_Test(data,data,configuration.treeNum,configuration.subsamplesize,anomaly)\n",
    "testing := Merge(testing_data[0], testing_data[1])\n",
    "\n",
    "\n",
    "testDatalen := len(testing)\n",
    "testData0len :=len(testing_data[0])\n",
    "\n",
    "labeldata:=BuildLabelsArray(testDatalen,testData0len)\n",
    "\n",
    "predictlabels,_,_ :=forestt.Predict(testing)\n",
    "fmt.Println(\"Predict Accuracy is...\",AccuracyScore(predictlabels,labeldata))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func dataLabelGenerator(numberofinstances int)([][]float64 ,[]int){\n",
    "\tdata := make([][]float64,0)\n",
    "\tlabels := make([]int,0)\n",
    "\tcount:=0\n",
    "\tfor j:=0; j<numberofinstances; j++{\n",
    "\t\tlabel := rand.Intn(2)\n",
    "\t\tlabels = append(labels,label)\n",
    "\t\tif label == 0 {\n",
    "\t\t\tdata = append(data,[]float64{0.0, 0.0})\n",
    "\t\t}else{\n",
    "\t\t\tdata= append(data,[]float64{1.1,1.1})\n",
    "\t\t\tcount++\n",
    "\t\t}\t\n",
    "\t} \n",
    "\n",
    "\t\n",
    "\treturn data,labels\n",
    "}\n",
    "\n",
    "func TestSplitDataset(ratio float64)(map[int][][]float64,map[int][][]float64, float64){\n",
    "\n",
    "\tdata,labels := dataLabelGenerator(532)\n",
    "\n",
    "\tdata_label_train,data_label_test,anomaly:=SplitDataset(data,labels,ratio)\n",
    "\ttrainlen0:=len(data_label_train[0])\n",
    "\ttrainlen1:=len(data_label_train[1])\n",
    "    testlen0:=len(data_label_test[0])\n",
    "\ttestlen1:=len(data_label_test[1]) \n",
    " \n",
    "    trainlen := trainlen0+trainlen1\n",
    "\ttestlen := testlen0+testlen1 \n",
    "\tright_train_len := int(float64(len(data))*ratio)\n",
    "\tright_test_len := int(float64(len(data))*(1-ratio))\n",
    "\tfmt.Println(\"SPLITDATASET METRICSSSSSSS\")\n",
    "\tfmt.Println(\"train length\",trainlen)\n",
    "\tfmt.Println(\"what train length should be\",right_train_len)\n",
    "\tfmt.Println(\"test length\",testlen)\n",
    "\tfmt.Println(\"what train test should be\",right_test_len)\n",
    "\n",
    "\ttraininganomaly := float64(trainlen1)/float64(trainlen)\n",
    "\ttestinganomaly := float64(testlen1)/float64(testlen)\n",
    "\n",
    "\tfmt.Println(\"real anomaly ratio\",anomaly)\n",
    "\tfmt.Println(\"training set anomaly ratio\",traininganomaly)\n",
    "\tfmt.Println(\"testing set anomaly ratio\",testinganomaly)\n",
    "\n",
    "\treturn \tdata_label_train,data_label_test,anomaly\n",
    "\n",
    "}\n",
    "\n",
    "func TestStratifiedKFold(){\n",
    "\n",
    "\tdata_label_train,_ ,anomaly:= TestSplitDataset(0.8)\n",
    "\tfmt.Println(\"KFOLD METRICSSSSSSS\")\n",
    "\tfor s := range StratifiedKFold(5,data_label_train){\n",
    "\t\ttraindatalen:=len(s.TrainData)\n",
    "\t\ttestdatalen:=len(s.ValidateData)\n",
    "\t\tvalidatedatalen:=len(s.ValidateData)\n",
    "\t\tKfoldtotallength:= traindatalen+validatedatalen\n",
    "\t\tInitiallen:= len(data_label_train[0])+len(data_label_train[1])\n",
    "\t\tfmt.Println(\"validate data length\",validatedatalen)\n",
    "\t\tfmt.Println(\"traindata length\",traindatalen)\n",
    "\t\tfmt.Println(\"total length length\", Kfoldtotallength)\n",
    "\t\tfmt.Println(\"should be the same as\", Initiallen)\n",
    "\t\tcount:=0\n",
    "\t\t//count1:=0\n",
    "\t\tfor _,v:= range s.LabelData{\n",
    "\t\t\tif v==1{\n",
    "\t\t\t\tcount++\n",
    "\t\t\t} \n",
    "\t\t}\n",
    "\t\t/* for _,v:= range s.trainLabelData{\n",
    "\t\t\tif v==1{\n",
    "\t\t\t\tcount1++\n",
    "\t\t\t} \n",
    "\t\t} */\n",
    "\t\ttestinganomaly:= float64(count)/float64(testdatalen)\n",
    "\t\t//traininganomaly:= float64(count1)/float64(traindatalen)\n",
    "\n",
    "\t\tfmt.Println(\"real anomaly ratio\",anomaly)\n",
    "\t\t//fmt.Println(\"Kfold training set anomaly ratio\",traininganomaly)\n",
    "\t\tfmt.Println(\"Kfold testing set anomaly ratio\",testinganomaly)\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "}\n",
    "\n",
    "%%\n",
    "\n",
    "TestStratifiedKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk Code :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func KFold(K int, datasetlen int)(ch chan Split){\n",
    "\n",
    "\tKpoint :=  int(math.Ceil(float64(datasetlen)/float64(K)))\n",
    "\tKpoints:=[]int{0}\n",
    "\n",
    "\tfor j:=1; j< K; j++{\n",
    "\t\tif Kpoints[j-1] + Kpoint >= datasetlen {\n",
    "\t\t\tbreak\n",
    "\t\t} \n",
    "\t\tKpoints = append(Kpoints, Kpoints[j-1] + Kpoint)\n",
    "\t\t\n",
    "\t}\n",
    "\tKpoints = append(Kpoints, datasetlen)\n",
    "\n",
    "    Indexes:=make([]int, datasetlen)\n",
    "\tfor i:=0; i<datasetlen; i++{\n",
    "\t\tIndexes[i]=i\n",
    "\t\t\n",
    "\t} \n",
    "\n",
    "\tch = make(chan Split)\n",
    "\t\n",
    "\tgo func(){\n",
    "\t\tvar sp *Split\n",
    "\t\tfor testsplit:=0; testsplit<K; testsplit++{\n",
    "\t\t\tif testsplit == 0{\n",
    "\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[:Kpoints[1]],\n",
    "\t\t\t\t\tTrainIndex:  Indexes[Kpoints[1]:],\t\t\t\t\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t}else if testsplit == K-1{\n",
    "\t\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[Kpoints[K-1]:],\n",
    "\t\t\t\t\tTrainIndex:  Indexes[:Kpoints[K-1]],\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\t\tbefore:= Indexes[:Kpoints[testsplit]]\n",
    "\t\t\t\t\tafter:= Indexes[Kpoints[testsplit+1]:]\n",
    "\t\t\t\t\tconcatenated:=make([]int, len(before)+len(after))\n",
    "\t\t\t\t\tcopy(concatenated, before)\n",
    "    \t\t\t\tcopy(concatenated[len(before):], after)\n",
    "\n",
    "\t\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[Kpoints[testsplit]:Kpoints[testsplit+1]],\n",
    "\t\t\t\t\tTrainIndex:  concatenated,\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\tch <-*sp\n",
    "\t\t}\n",
    "\t\tclose(ch)\n",
    "\t}()\n",
    "\treturn ch\n",
    "\n",
    "}\n",
    "func getElements(indexTrain []int ,indexTest []int ,dataArray [][]float64, labelsArray []int)([][]float64,[][]float64, []int) {\n",
    "\tdataTrain := make([][]float64, len(indexTrain))\n",
    "\tdataTest := make([][]float64, len(indexTest))\n",
    "\tlabels := make([]int, len(indexTest))\n",
    "\t\n",
    "\tfor i, index := range indexTrain {\n",
    "\t\tdataTrain[i] = dataArray[index]\n",
    "\t}\n",
    "\tfor i, index := range indexTest {\n",
    "\t\tdataTest[i] = dataArray[index]\n",
    "\t\tlabels[i] = labelsArray[index]\n",
    "\n",
    "\t}\n",
    "\treturn dataTrain,dataTest,labels\n",
    "}\n",
    "\n",
    " func CrossValidation(dataset string){\n",
    "\t\n",
    "\ti:=1\n",
    "\tdata:=loadData(dataset)\n",
    "\tlabels:=LoadLabels(\"training_labels.csv\")\n",
    "\tfor s := range KFold(5,len(data)){\n",
    "\t\tfmt.Println(\"%Iteration N.\",i)\n",
    "\t\ti++\n",
    "\t\ttraindata,testdata,labeldata := getElements(s.TrainIndex,s.TestIndex,data,labels)\n",
    "\t\tforest:=isoForestTrain_Test(traindata, testdata,100,1000,0.8)\n",
    "\t\tAccuracyScore(forest.Labels,labeldata)\n",
    "\t\tF1Score(forest.Labels,labeldata)\t\n",
    "\t}\n",
    "\n",
    "}\n",
    "%%\n",
    "/* data := loadData(\"training.csv\")\n",
    "fmt.Println(data)\n",
    "//datasetlen:=len(data)\n",
    "for s := range KFold(5,data){\n",
    "\tfmt.Println(s.TrainData)\n",
    "\t\n",
    "} */\n",
    "\n",
    "cache.ResetKey(\"my_forest\")\n",
    "var forest = cache.Cache(\"my_forest\", func() * iforest.Forest {return isoForestTrain_Test(data,data,configuration.treeNum,configuration.subsamplesize,outlier)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.21.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
