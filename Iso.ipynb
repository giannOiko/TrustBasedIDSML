{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\t\"github.com/pa-m/sklearn/metrics\"\n",
    "\t    li \"github.com/pa-m/sklearn/linear_model\"\n",
    "\t\tms \"github.com/pa-m/sklearn/model_selection\"\n",
    "\t\t\"github.com/e-XpertSolutions/go-iforest/iforest\"\t\n",
    "\t\t\"bufio\"\n",
    "\t\t\"encoding/csv\"\n",
    "\t\t\"strconv\"\n",
    "\t\t\"github.com/janpfeifer/gonb/gonbui\"\n",
    "\t\t\"gonum.org/v1/plot/plotutil\"\n",
    "\t\t\"gonum.org/v1/plot\"\n",
    "\t\t\"gonum.org/v1/plot/plotter\"\n",
    "\t\t\"gonum.org/v1/plot/vg\"\n",
    "\t\t\"gonum.org/v1/plot/vg/draw\"\n",
    "\t\t\"os/exec\"\n",
    "\t\t\"github.com/janpfeifer/gonb/cache\"\n",
    "\t\t\"math\"\n",
    "\t\t\"math/rand\"\n",
    "\n",
    "\t)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".gonb-err-location {\n",
       "\tbackground: var(--jp-err-color2);  \n",
       "\tborder-radius: 3px;\n",
       "\tborder-style: dotted;\n",
       "\tborder-width: 1px;\n",
       "\tborder-color: var(--jp-border-color2);\n",
       "}\n",
       ".gonb-err-location:hover {\n",
       "\tborder-width: 2px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: var(--jp-border-color2);\n",
       "}\n",
       ".gonb-err-context {\n",
       "\tdisplay: none;\n",
       "}\n",
       ".gonb-err-location:hover + .gonb-err-context {\n",
       "\tbackground: var(--jp-dialog-background);  \n",
       "\tborder-radius: 3px;\n",
       "\tborder-style: solid;\n",
       "\tborder-width: 1px;\n",
       "\tborder-color: var(--jp-border-color2);\n",
       "\tdisplay: block;\n",
       "\twhite-space: pre;\n",
       "\tfont-family: monospace;\n",
       "}\n",
       ".gonb-err-line {\n",
       "\tborder-radius: 3px;\n",
       "\tborder-style: dotted;\n",
       "\tborder-width: 1px;\t\n",
       "\tborder-color: var(--jp-border-color2);\n",
       "\tbackground-color: var(--jp-rendermime-err-background);\n",
       "\tfont-weight: bold;\n",
       "}\n",
       ".gonb-cell-line-info {\n",
       "\tbackground: var(--jp-layout-color2);\n",
       "\tcolor: #999;\n",
       "\tmargin: 0.1em;\n",
       "\tborder: 1px solid var(--jp-border-color1);\n",
       "\tpadding-left: 0.2em;\n",
       "\tpadding-right: 0.2em;\n",
       "}\n",
       "</style>\n",
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-OutputArea-child\">\n",
       "<div class=\"lm-Widget p-Widget jp-RenderedText jp-mod-trusted jp-OutputArea-output\" data-mime-type=\"application/vnd.jupyter.stderr\" style=\"font-family: monospace;\">\n",
       "\n",
       "\n",
       "<span style=\"white-space: pre;\"> # github.com/pa-m/optimize</span>\n",
       "\n",
       "<br/>\n",
       "\n",
       "\n",
       "<span style=\"white-space: pre;\"> /home/ze/go/pkg/mod/github.com/pa-m/optimize@v0.0.0-20190612075243-15ee852a6d9a/cmaesbounded.go:210:23: cma.InitCholesky.Symmetric undefined (type *mat.Cholesky has no field or method Symmetric)</span>\n",
       "\n",
       "<br/>\n",
       "\n",
       "\n",
       "<span style=\"white-space: pre;\"> </span>\n",
       "\n",
       "<br/>\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "failed to run \"/usr/local/go/bin/go build -o /tmp/gonb_83ae79fd/gonb_83ae79fd\": exit status 1",
     "output_type": "error",
     "traceback": [
      "failed to run \"/usr/local/go/bin/go build -o /tmp/gonb_83ae79fd/gonb_83ae79fd\": exit status 1"
     ]
    }
   ],
   "source": [
    "type Split struct{\n",
    "\tTrainData [][] float64\n",
    "\tValidateData [][] float64\n",
    "\tLabelData []int\n",
    "\t//trainLabelData []int for unit testing\n",
    "\t}\n",
    "\n",
    "type config struct{\n",
    "\ttreeNum int\n",
    "\tsubsamplesize int\n",
    "}\n",
    "\n",
    "//load file Data and Return [][]float64 array\n",
    "func loadData(myfile string) [][]float64 {\n",
    "\n",
    "\tl:=false\n",
    "file, err := os.Open(myfile)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error opening file:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\n",
    "\treader := csv.NewReader(file)\n",
    "\trecords, err := reader.ReadAll()\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error reading CSV:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\t\n",
    "\tinputData := make([][]float64, len(records))\n",
    "\tfor i, row := range records {\n",
    "\n",
    "\t\tinputData[i] = make([]float64, len(row))\n",
    "\t\tfor j, value := range row {\n",
    "\t\t\tinputData[i][j], err = strconv.ParseFloat(value, 64)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tfmt.Printf(\"Error converting to float: line %d\",i)\n",
    "\t\t\t\tl=true\n",
    "\t\t\t\tbreak\t\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tif l == true{\n",
    "\t\t\tbreak\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn inputData\n",
    "}\n",
    "\n",
    "func LoadLabels(filePath string)[]int{\n",
    "\tfile, err := os.Open(filePath)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error opening file:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\n",
    "\tscanner := bufio.NewScanner(file)\n",
    "\t\n",
    "\tvar labels []int\n",
    "\n",
    "\tfor scanner.Scan() {\n",
    "\t\tlabel,err := strconv.Atoi(scanner.Text())\n",
    "\t\tif err != nil {\n",
    "\t\t\t// Handle the error if the conversion fails\n",
    "\t\t\tfmt.Println(\"Error:\", err)\n",
    "\t\t\treturn nil\n",
    "\t\t}\n",
    "\t\tlabels= append(labels,label)\n",
    "\t}\n",
    "\treturn labels\n",
    "}\n",
    "\n",
    "//Convert labels to float for F1 and Accuracy Score metrics\n",
    "func ConvertToFloat(int_array []int)([]float64){\n",
    "\n",
    "\tlength :=len(int_array)\n",
    "\tfloat_array := make([]float64, length)\n",
    "\n",
    "\tfor i:=0; i<length; i++ {\n",
    "\t\t\n",
    "\t\tfloat_array[i] = float64(int_array[i])\n",
    "\t}\n",
    "\treturn float_array\n",
    "\n",
    "}\n",
    "\n",
    "func F1Score(labelsPred []int, labelsTru []int) float64{\n",
    "\n",
    "\tpred:= ConvertToFloat(labelsPred)\n",
    "\ttru := ConvertToFloat(labelsTru)\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\tvar sampleWeight []float64\n",
    "\t/* fmt.Printf(\"F1 macro %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"macro\", sampleWeight))\n",
    "\tfmt.Printf(\"F1 micro %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"micro\", sampleWeight))\n",
    "\tfmt.Printf(\"F1 weighted %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"weighted\", sampleWeight)) */\n",
    "\treturn metrics.F1Score(Ytrue, Ypred, \"weighted\", sampleWeight)\n",
    "\n",
    "}\n",
    "\n",
    "func AccuracyScore(labelsPred []int, labelsTru []int)float64{\n",
    "\n",
    "\tpred:= ConvertToFloat(labelsPred)\n",
    "\ttru := ConvertToFloat(labelsTru)\n",
    "\n",
    "\tvar nilDense *mat.Dense\n",
    "\tnormalize, sampleWeight := true, nilDense\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\treturn metrics.AccuracyScore(Ytrue, Ypred, normalize, sampleWeight)\n",
    "\n",
    "}\n",
    "\n",
    "func RocAucScore(labelsPred []int, labelsTru []int)float64{\n",
    "\tpred:= ConvertToFloat(labelsPred)\n",
    "\ttru := ConvertToFloat(labelsTru)\n",
    "\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\treturn metrics.ROCAUCScore(Ytrue, Ypred, \"weighted\", nil)\n",
    "}\n",
    "\n",
    "// call command line executable\n",
    "func prepareDataset(dataset string){\n",
    "\tcmd :=exec.Command(\"./extract_splitDataset.sh\", dataset)\n",
    "\tcmd.Run()\n",
    "}\n",
    "\n",
    "func Mean(array []float64)float64{\n",
    "\tsum := 0.0\n",
    "    for _, num := range array {\n",
    "        sum += num\n",
    "    }\n",
    "\n",
    "    // Calculate the mean\n",
    "    mean := sum / float64(len(array))\n",
    "\treturn mean\n",
    "}\n",
    "\n",
    "func outlierRatio(lab []int) float64{\n",
    "\tcount :=0 \n",
    "\tfor _,v := range lab{\n",
    "\t\tif v == 1{\n",
    "\t\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\tanomaly := float64(count)/float64(len(lab))\n",
    "\treturn anomaly\n",
    "}\n",
    "\n",
    "func findMaxIndex(arr []float64)int{\n",
    "\n",
    "\tmaxIndex := 0 \n",
    "\n",
    "    for i := 1; i < len(arr); i++ {\n",
    "     \n",
    "        if arr[i] > arr[maxIndex] {\n",
    "            maxIndex = i\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return maxIndex \n",
    "}\n",
    "\n",
    "\n",
    "func BuildLabelsArray(lendata int, lenzerodata int)[]int{\n",
    "\n",
    "\n",
    "labeldata := make([]int, lendata)\n",
    "\t\t\tfor i:=0; i<lendata; i++{\n",
    "\t\t\t\tif i < lenzerodata{\n",
    "\t\t\t\tlabeldata[i] = 0\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\tlabeldata[i] = 1\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\treturn labeldata\n",
    "}\n",
    "\n",
    "func findBestConfig(themap map[config][]float64)*config{\n",
    "\t\n",
    "\thighest_mean := 0.0\n",
    "\tvar bestconf *config\n",
    "\tfor conf,f1s := range themap{\n",
    "\t\tmean := Mean(f1s)\t\n",
    "\t\t\n",
    "\t\tif mean > highest_mean{\n",
    "\t\t\thighest_mean = mean\n",
    "\t\t\tbestconf = &config{\n",
    "                treeNum:       conf.treeNum,\n",
    "                subsamplesize: conf.subsamplesize,\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"Highest mean is: \",highest_mean)\n",
    "\treturn bestconf\n",
    "}\n",
    "func ShuffleDataset(dataset [][]float64, labels []int){\n",
    "\t\n",
    "\trand.Shuffle(len(labels), func(i, j int) {\n",
    "\t\tdataset[i], dataset[j] = dataset[j], dataset[i]\n",
    "\t\tlabels [i], labels[j] = labels[j], labels[i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func flatten2D(arr [][]float64) []float64 {\n",
    "    var flattened []float64\n",
    "    for _, row := range arr {\n",
    "        flattened = append(flattened, row...)\n",
    "    }\n",
    "    return flattened\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Isolation Forest algorithm\n",
    "\n",
    "func isoForestTrain_Test(training_data [][]float64 ,testing_data [][]float64 , treesNumber int, subsampleSize int, outliers float64) *iforest.Forest{\n",
    "//model initialization\n",
    "forest := iforest.NewForest(treesNumber, subsampleSize, outliers)\n",
    "\n",
    "//training stage - creating trees\n",
    "forest.Train(training_data)\n",
    "\n",
    "//testing stage - finding anomalies \n",
    "forest.Test(testing_data)\n",
    "\n",
    "//threshold := forest.AnomalyBound\n",
    "//labels := forest.Labels\n",
    "\n",
    "//fmt.Println(\"threshold is\",threshold)\n",
    "\n",
    "return forest;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data, K-Fold Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "func SplitDataset (dataset [][]float64, labels[]int, splitRatio float64)(map[int][][]float64,map[int][][]float64,float64){\n",
    "\n",
    "\tmyMap := make(map[int][][]float64)\n",
    "\tTrainingIndex_Data := make(map[int][][]float64)\n",
    "\tTestingIndex_Data := make(map[int][][]float64)\n",
    "\tcount:=0\n",
    "\tfor i,instance:= range dataset{\n",
    "\t\tif labels[i] == 0{\n",
    "\t\tmyMap[0] = append(myMap[0], instance)\n",
    "\t\t}else{\n",
    "\t\tmyMap[1] = append(myMap[1], instance)\n",
    "\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\tShuffleUnit(myMap)\n",
    "\tsplit0:= int(math.Round(splitRatio * float64(len(myMap[0]))))\n",
    "\tsplit1:= int(math.Round(splitRatio * float64(len(myMap[1]))))\n",
    "\n",
    "\tTrainingIndex_Data[0] = myMap[0][:split0]\n",
    "\tTrainingIndex_Data[1] = myMap[1][:split1]\n",
    "\tTestingIndex_Data[0] = myMap[0][split0:]\n",
    "\tTestingIndex_Data[1] = myMap[1][split1:] \n",
    "\n",
    "\tanomaly := float64(count)/float64(len(labels))\n",
    "\treturn  TrainingIndex_Data, TestingIndex_Data, anomaly\n",
    "}\n",
    "\n",
    "func Shuffle(testing_set [][]float64, training_set [][]float64, label_set []int){\n",
    "\n",
    "\trand.Shuffle(len(training_set), func(i, j int) {\n",
    "\t\ttraining_set[i], training_set[j] = training_set[j], training_set[i]\n",
    "\t})\n",
    "\trand.Shuffle(len(testing_set), func(i, j int) {\n",
    "\t\ttesting_set[i], testing_set[j] = testing_set[j], testing_set[i]\n",
    "\t\tlabel_set [i], label_set[j] = label_set[j], label_set[i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func ShuffleUnit(data_label map[int][][]float64){\n",
    "\n",
    "\trand.Shuffle(len(data_label[0]), func(i, j int) {\n",
    "\t\tdata_label[0][i], data_label[0][j] = data_label[0][j], data_label[0][i]\n",
    "\t})\n",
    "\trand.Shuffle(len(data_label[1]), func(i, j int) {\n",
    "\t\tdata_label[1][i], data_label[1][j] = data_label[1][j], data_label[1][i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func StratifiedKFold(K int, data_label map[int][][]float64)(ch chan Split){\n",
    "\n",
    "\n",
    "\tfoldSizezeros:= int(math.Round(float64((len(data_label[0])/K))))\n",
    "\tfoldSizeones:= int(math.Round((float64(len(data_label[1])/K))))\n",
    "\n",
    "\tch = make(chan Split)\n",
    "\t\n",
    "\tgo func(){\n",
    "\t\t\n",
    "\t\tvar sp *Split\n",
    "\t\tfor i:=0; i<K; i++{\n",
    "\t\t\tstartIndex0 := i * foldSizezeros\n",
    "\t\t\tendIndex0 := (i + 1) * foldSizezeros\n",
    "\t\t\tstartIndex1 := i * foldSizeones\n",
    "\t\t\tendIndex1 := (i + 1) * foldSizeones\n",
    "\n",
    "\t\t\tif i == K-1 {\n",
    "\t\t\t\tendIndex0 = len(data_label[0])\n",
    "\t\t\t\tendIndex1 = len(data_label[1])\n",
    "\t\t\t}\n",
    "\t\t\ttrainData0 := make([][]float64, 0)\n",
    "\t\t\ttrainData1 := make([][]float64, 0)\n",
    "\n",
    "\t\t\t// Merge all data except the test data into the training data\n",
    "\t\t\ttrainData0 = append(trainData0, data_label[0][:startIndex0]...)\n",
    "\t\t\ttrainData0 = append(trainData0, data_label[0][endIndex0:]...)\n",
    "\t\t\ttrainData1 = append(trainData1, data_label[1][:startIndex1]...)\n",
    "\t\t\ttrainData1 = append(trainData1, data_label[1][endIndex1:]...)\n",
    "\t\t\t\n",
    "\t\t\ttrainData := Merge(trainData0,trainData1)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\tvalidData0:=data_label[0][startIndex0:endIndex0]\n",
    "\t\t\tvalidData1:=data_label[1][startIndex1:endIndex1]\n",
    "\t\t\t\n",
    "\t\t\tvalidData := Merge(validData0, validData1)\n",
    "\n",
    "\t\t\tvalidDatalen:= len(validData)\n",
    "\t\t\n",
    "\t\t    labeldata:= BuildLabelsArray(validDatalen,len(validData0))\n",
    "\t\t\t\n",
    "\t\t\tShuffle(validData,trainData,labeldata)\n",
    "\t\t\t\n",
    "\t\t\tsp = &Split{\n",
    "\t\t\t\tTrainData: trainData,\n",
    "\t\t\t\tValidateData:  validData,\n",
    "\t\t\t\tLabelData: labeldata,\n",
    "\t\t\t\t//trainLabelData: trainlabeldata,\n",
    "\t\t\t}\n",
    "\t\t\tch <- *sp\n",
    "\t\t}\n",
    "\t\tclose(ch)\t\n",
    "\t}()\n",
    "\treturn ch\n",
    "}\n",
    "\n",
    "func Merge(data1 [][]float64, data2 [][]float64)[][]float64{\n",
    "\n",
    "\tconcatenated:=make([][]float64, len(data1)+len(data2))\n",
    "\t\t\t\t\tcopy(concatenated, data1)\n",
    "    \t\t\t\tcopy(concatenated[len(data1):], data2)\n",
    "\treturn concatenated\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func GridSearchCV(data map[int][][]float64,treenummax int,subsamplmax int,anomaly float64) *config{\n",
    "\n",
    "\tConfF1s := make(map[config][]float64,0)\n",
    "\tvar conf config\n",
    "\ti := 1\n",
    "\t\n",
    "\tfor s := range StratifiedKFold(5,data){\t\n",
    "\t\ttreenumStep := 10\n",
    "\t\tfmt.Println(\"Entering Iteration num \",i)\n",
    "\t\tfor tr_n :=10 ;tr_n <=treenummax; tr_n+= treenumStep{\n",
    "\t\t\tfor sss := 50; sss<=subsamplmax; sss+= 50{\n",
    "\t\t\t\tconf = config{\n",
    "\t\t\t\t\ttreeNum:tr_n,\n",
    "\t\t\t\t\tsubsamplesize:sss,\n",
    "\t\t\t\t}\n",
    "\t\t\t\tforest:=isoForestTrain_Test(s.TrainData, s.ValidateData,tr_n,sss,anomaly)\n",
    "\t\t\t\tf1Score := F1Score(s.LabelData,forest.Labels)\n",
    "\t\t\t\tConfF1s[conf] = append(ConfF1s[conf],f1Score)\n",
    "\t\t\t}\n",
    "\t\t\tif tr_n == 100{\n",
    "\t\t\t\ttreenumStep = 100\n",
    "\t\t\t}else if tr_n == 1000{\n",
    "\t\t\t\ttreenumStep = 500\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\ti++\n",
    "\t}\n",
    "\tbestConfig:=findBestConfig(ConfF1s)\n",
    "\tfmt.Println(ConfF1s)\n",
    "\t\n",
    "\treturn bestConfig\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%\n",
    "//load from files the pr \n",
    "data:=loadData(\"dataset.csv\")\n",
    "labels:=LoadLabels(\"labels.csv\")\n",
    "\n",
    "training_data , testing_data , anomaly :=  SplitDataset(data,labels,0.8)\n",
    "fmt.Println(\"anomaly ratio is: \",anomaly)\n",
    "\n",
    "configuration := GridSearchCV(training_data,2000,350,anomaly) //returns the Best configuration {treeNum}{SubsamplingSize}\n",
    "\n",
    "\n",
    "//train with the best conf\n",
    "fmt.Println(\"Training Model with parameters... \",configuration)\n",
    "forestt := isoForestTrain_Test(data,data,configuration.treeNum,configuration.subsamplesize,anomaly)\n",
    "\n",
    "//prepare the testing data for predict\n",
    "testing := Merge(testing_data[0], testing_data[1])\n",
    "\n",
    "testDatalen := len(testing)\n",
    "testData0len :=len(testing_data[0])\n",
    "\n",
    "labeldata:=BuildLabelsArray(testDatalen,testData0len)\n",
    "\n",
    "\n",
    "predictlabels,_,_ :=forestt.Predict(testing)\n",
    "fmt.Println(\"Predict Accuracy is...\",AccuracyScore(predictlabels,labeldata))\n",
    "fmt.Println(\"Predict F1 is...\",F1Score(predictlabels,labeldata))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest mean F1 is:  0.7177943161752799\n",
    "\n",
    "Training Model with parameters...  &{20 200}\n",
    "\n",
    "Predict Accuracy is... 0.921764804412011\n",
    "\n",
    "Predict F1 is... 0.707546012323603"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5247991510703078\n",
      "9.175657275024252\n",
      "Predict Accuracy is... 0.41657488522454994\n",
      "Predict F1 is... 0.4151366531090248\n",
      "Predict ROC/AUC is.. 0.415136729761694\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "data:=loadData(\"dataset.csv\")\n",
    "labels:=LoadLabels(\"labels.csv\")\n",
    "anomaly:= outlierRatio(labels)\n",
    "fmt.Println(anomaly)\n",
    "ShuffleDataset(data,labels)\n",
    "\n",
    "\n",
    "forestt := isoForestTrain_Test(data,data,90,150,anomaly)\n",
    "predict_labels := forestt.Labels\n",
    "fmt.Println(\"Predict Accuracy is...\",AccuracyScore(labels,predict_labels))\n",
    "fmt.Println(\"Predict F1 is...\",F1Score(labels,predict_labels))\n",
    "fmt.Println(\"Predict ROC/AUC is..\",RocAucScore(labels,predict_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leeenn 121621\n",
      "zeros is min\n",
      "map[Alpha:[1e-10 1e-09 1e-08 1e-07 1e-06 9.999999999999999e-06 9.999999999999999e-05 0.001 0.01 0.1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "signal: killed\n"
     ]
    }
   ],
   "source": [
    "//Make dataset Balanced with undersampling for optimal lasso regression\n",
    "func BalanceData (dataset [][]float64, labels []int)([][]float64,[]int){\n",
    "\n",
    "\t//get 0's and 1's from dataset\n",
    "\tmyMap := make(map[int][][]float64)\n",
    "\tcount:=0\n",
    "\tfor i,instance:= range dataset{ \n",
    "\t\tif labels[i] == 0{\n",
    "\t\tmyMap[0] = append(myMap[0], instance)\n",
    "\t\t}else{\n",
    "\t\tmyMap[1] = append(myMap[1], instance)\n",
    "\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tShuffleUnit(myMap)\n",
    "\t\n",
    "\t// determine minority and majority class\n",
    "\tvar MajorityClass, MinorityClass [][]float64 \n",
    "\tvar Maj bool\n",
    "\tif len(myMap[0])>len(myMap[1]){\n",
    "\t\tMajorityClass = make([][]float64,len(myMap[0]))\n",
    "\t\tMinorityClass = make([][]float64,len(myMap[1]))\n",
    "\t\tcopy(MajorityClass,myMap[0])\n",
    "\t\tcopy(MinorityClass,myMap[1])\n",
    "\t\tMaj = true\n",
    "\t}else{\n",
    "\t\tMajorityClass = make([][]float64,len(myMap[1]))\n",
    "\t\tMinorityClass = make([][]float64,len(myMap[0]))\n",
    "\t\tcopy(MajorityClass,myMap[1])\n",
    "\t\tcopy(MinorityClass,myMap[0])\n",
    "\t\tMaj = false\n",
    "\t}\n",
    "\n",
    "\tfmt.Println(\"leeenn\",len(MinorityClass))\n",
    "\t\n",
    "\t/* fmt.Println(MajorityClass)\n",
    "\tfmt.Println(MinorityClass) */\n",
    "\n",
    "\t// shuffle majority class for unbiased sampling\n",
    "\trand.Shuffle(len(MajorityClass), func(i, j int) {\n",
    "\t\tMajorityClass[i], MajorityClass[j] = MajorityClass[j], MajorityClass[i]\n",
    "\t})\n",
    "\n",
    "\t// undersample majority class in length of minority class\n",
    "\tEqualClass := MajorityClass[:len(MinorityClass)] \n",
    "\n",
    "\t//Merge both classes\n",
    "\tvar lenzerodata int\n",
    "\tvar data [][]float64\n",
    "\tif (Maj){\n",
    "\t\tdata = Merge(EqualClass,MinorityClass)\n",
    "\t\tlenzerodata = len(EqualClass)\n",
    "\t\tfmt.Println(\"zeros is maj\")\n",
    "\t}else{\n",
    "\t\tdata = Merge(MinorityClass,EqualClass)\n",
    "\t\tlenzerodata = len(MinorityClass)\n",
    "\t\tfmt.Println(\"zeros is min\")\n",
    "\t}\n",
    "\n",
    "\t//build new labels like the data we sampled\n",
    "\tlab := BuildLabelsArray(len(data), lenzerodata)\n",
    "\n",
    "\t//shuffle the new dataset\n",
    "\tShuffleDataset(data,lab)\n",
    "\n",
    "\treturn data,lab\n",
    "\t\n",
    "}\n",
    "\n",
    "\n",
    "func nearlyEqual(a, b float64) bool {\n",
    "    const epsilon  = 2.220446049250313e-4 //FLT_EPSILON for float64\n",
    "\n",
    "    // Absolute difference between a and b\n",
    "    diff := math.Abs(a - b)\n",
    "\n",
    "    // Check if the difference is less than or equal to epsilon\n",
    "    return diff <= epsilon\n",
    "}\n",
    "\n",
    "func LassoGridSearchCV(data [][]float64, labels []int)([]int){\n",
    "\n",
    "\t//Get balanced data\n",
    "\tBalanced_Data, Balanced_Labels := BalanceData(data,labels)\n",
    "\t\n",
    "\tNSamples:=len(Balanced_Labels)\n",
    "\tNFeatures:=len(Balanced_Data[0])\n",
    "\n",
    "\t//Create data and label matrices\n",
    "\tX, Y := mat.NewDense(NSamples, NFeatures, flatten2D(Balanced_Data)), mat.NewDense(NSamples, 1, ConvertToFloat(Balanced_Labels))\n",
    "\n",
    "\t//initialiaze lasso parameters\n",
    "\tlasso := li.NewLasso()\n",
    "\tlasso.FitIntercept = true\n",
    "\tlasso.Normalize = true\n",
    "\tlasso.L1Ratio = 1\n",
    "\tlasso.MaxIter = 1e5\n",
    "\tlasso.Tol = 1e-4 \n",
    "\n",
    "\t//Make alpha parameter grid. Static from 1e-10 multiplied by 10, 10 times until 0.1.\n",
    "\tgridLength := 10\n",
    "\tstart_value := 1e-10\n",
    "\n",
    "\ttype ParamGrid map[string][]interface{}\n",
    "\n",
    "\tparamGrid := ParamGrid{\n",
    "\t\t\"Alpha\": make([]interface{}, gridLength),\n",
    "\t}\n",
    "\n",
    "\tfor i := 0; i < gridLength; i++ {\n",
    "\t\tparamGrid[\"Alpha\"][i] = start_value\n",
    "\t\tstart_value = start_value * 10 \n",
    "\t}\n",
    "\n",
    "\tfmt.Println(paramGrid)\n",
    "\n",
    "\t//Scorer is R2\n",
    "\tscorer := func(Y, Ypred mat.Matrix) float64 {\n",
    "\t\treturn metrics.R2Score(Y, Ypred, nil, \"\").At(0, 0)\n",
    "\t}\n",
    "\n",
    "\tRandomState := base.NewLockedSource(7)\n",
    "\n",
    "\t//Instatiate Grid Search CV for lasso regression.. 3 repetitions K-Fold\n",
    "\tlassocv := &ms.GridSearchCV{\n",
    "\t\tEstimator: lasso,\n",
    "\t\tParamGrid: paramGrid,\n",
    "\t\tScorer:             scorer,\n",
    "\t\tLowerScoreIsBetter: true,\n",
    "\t\tCV:                 &ms.KFold{NSplits: 3, RandomState: RandomState, Shuffle: true},\n",
    "\t\tVerbose: true,\n",
    "\t\tNJobs:   -1}\n",
    "\n",
    "\t//Run Grid Search CV\n",
    "\tlassocv.Fit(X, Y)\n",
    "\tfmt.Println(\"Alpha\", lassocv.BestParams[\"Alpha\"]) \n",
    "\n",
    "\t//Set lasso ALpha the best returned ALpha from CV\n",
    "\tlasso.Alpha = lassocv.BestParams[\"Alpha\"].(float64)\n",
    "\n",
    "\t//Run lasso regression\n",
    "\tlasso.Fit(X,Y)\n",
    "\n",
    "\t//Predict coefficients see which are set to 0 and return the indexes that are not zero\n",
    "\tcoef := lasso.Coef\n",
    "\tr,_ := coef.Dims()\n",
    "\tindexes := make([]int,0)\n",
    "\t\n",
    "\tfor i := 0; i < r; i++ {\n",
    "            value := coef.At(i, 0)\n",
    "\t\t\tfmt.Printf(\"Matrix[%d][0]: %.5f\\n\", i, value)\n",
    "\t\t\t//valuee := float64(value)\n",
    "\t\t\tif !nearlyEqual(value,0.0){\n",
    "\t\t\t\tindexes = append(indexes,i)\n",
    "\t\t\t}\n",
    "\t\t\n",
    "    }\n",
    "\n",
    "\tfmt.Printf(\"columns to keep = %v\",indexes )\n",
    "\treturn indexes   \n",
    "}\n",
    "\n",
    "//remove zero coefficient columns from dataset \n",
    "func removeColumns(dataset [][]float64, columnsToKeep []int)([][]float64){\n",
    "\n",
    "\tnewDataset := make([][]float64, len(dataset))\n",
    "    for i := range newDataset {\n",
    "        newDataset[i] = make([]float64, len(dataset[i])-len(columnsToKeep))\n",
    "    }\n",
    "\n",
    "\tfor i,row := range dataset{\n",
    "\t\tnewRow := make([]float64,0)\n",
    "\t\tfor col, value := range row{\n",
    "\t\t\tfor _,keepcol := range columnsToKeep{\n",
    "\t\t\t\tif col == keepcol{\n",
    "\t\t\t\t\tnewRow = append(newRow,value)\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t}\n",
    "\t\t\t}\t \n",
    "\t\t}\n",
    "\t\tnewDataset[i] = newRow\n",
    "\t}\n",
    "\treturn newDataset\n",
    "}\n",
    "\n",
    "\n",
    "%%\n",
    "data:=loadData(\"Mirai_dataset.csv\")\n",
    "labels:=LoadLabels(\"mirai_labels.csv\")\n",
    "\n",
    "indexes := LassoGridSearchCV(data,labels)\n",
    "fmt.Println(indexes)\n",
    "//NewDataset := removeColumns(data,indexes)\n",
    "/* fmt.Println(data)\n",
    "fmt.Println(len(data))\n",
    "fmt.Println(NewDataset)\n",
    "fmt.Println(len(NewDataset))   */\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func dataLabelGenerator(numberofinstances int)([][]float64 ,[]int){\n",
    "\tdata := make([][]float64,0)\n",
    "\tlabels := make([]int,0)\n",
    "\tcount:=0\n",
    "\tfor j:=0; j<numberofinstances; j++{\n",
    "\t\tlabel := rand.Intn(2)\n",
    "\t\tlabels = append(labels,label)\n",
    "\t\tif label == 0 {\n",
    "\t\t\tdata = append(data,[]float64{0.0, 0.0})\n",
    "\t\t}else{\n",
    "\t\t\tdata= append(data,[]float64{1.1,1.1})\n",
    "\t\t\tcount++\n",
    "\t\t}\t\n",
    "\t} \n",
    "\n",
    "\t\n",
    "\treturn data,labels\n",
    "}\n",
    "\n",
    "func TestSplitDataset(ratio float64)(map[int][][]float64,map[int][][]float64, float64){\n",
    "\n",
    "\tdata,labels := dataLabelGenerator(532)\n",
    "\n",
    "\tdata_label_train,data_label_test,anomaly:=SplitDataset(data,labels,ratio)\n",
    "\ttrainlen0:=len(data_label_train[0])\n",
    "\ttrainlen1:=len(data_label_train[1])\n",
    "    testlen0:=len(data_label_test[0])\n",
    "\ttestlen1:=len(data_label_test[1]) \n",
    " \n",
    "    trainlen := trainlen0+trainlen1\n",
    "\ttestlen := testlen0+testlen1 \n",
    "\tright_train_len := int(float64(len(data))*ratio)\n",
    "\tright_test_len := int(float64(len(data))*(1-ratio))\n",
    "\tfmt.Println(\"SPLITDATASET METRICSSSSSSS\")\n",
    "\tfmt.Println(\"train length\",trainlen)\n",
    "\tfmt.Println(\"what train length should be\",right_train_len)\n",
    "\tfmt.Println(\"test length\",testlen)\n",
    "\tfmt.Println(\"what train test should be\",right_test_len)\n",
    "\n",
    "\ttraininganomaly := float64(trainlen1)/float64(trainlen)\n",
    "\ttestinganomaly := float64(testlen1)/float64(testlen)\n",
    "\n",
    "\tfmt.Println(\"real anomaly ratio\",anomaly)\n",
    "\tfmt.Println(\"training set anomaly ratio\",traininganomaly)\n",
    "\tfmt.Println(\"testing set anomaly ratio\",testinganomaly)\n",
    "\n",
    "\treturn \tdata_label_train,data_label_test,anomaly\n",
    "\n",
    "}\n",
    "\n",
    "func TestStratifiedKFold(){\n",
    "\n",
    "\tdata_label_train,_ ,anomaly:= TestSplitDataset(0.8)\n",
    "\tfmt.Println(\"KFOLD METRICSSSSSSS\")\n",
    "\tfor s := range StratifiedKFold(5,data_label_train){\n",
    "\t\ttraindatalen:=len(s.TrainData)\n",
    "\t\ttestdatalen:=len(s.ValidateData)\n",
    "\t\tvalidatedatalen:=len(s.ValidateData)\n",
    "\t\tKfoldtotallength:= traindatalen+validatedatalen\n",
    "\t\tInitiallen:= len(data_label_train[0])+len(data_label_train[1])\n",
    "\t\tfmt.Println(\"validate data length\",validatedatalen)\n",
    "\t\tfmt.Println(\"traindata length\",traindatalen)\n",
    "\t\tfmt.Println(\"total length length\", Kfoldtotallength)\n",
    "\t\tfmt.Println(\"should be the same as\", Initiallen)\n",
    "\t\tcount:=0\n",
    "\t\t//count1:=0\n",
    "\t\tfor _,v:= range s.LabelData{\n",
    "\t\t\tif v==1{\n",
    "\t\t\t\tcount++\n",
    "\t\t\t} \n",
    "\t\t}\n",
    "\t\t/* for _,v:= range s.trainLabelData{\n",
    "\t\t\tif v==1{\n",
    "\t\t\t\tcount1++\n",
    "\t\t\t} \n",
    "\t\t} */\n",
    "\t\ttestinganomaly:= float64(count)/float64(testdatalen)\n",
    "\t\t//traininganomaly:= float64(count1)/float64(traindatalen)\n",
    "\n",
    "\t\tfmt.Println(\"real anomaly ratio\",anomaly)\n",
    "\t\t//fmt.Println(\"Kfold training set anomaly ratio\",traininganomaly)\n",
    "\t\tfmt.Println(\"Kfold testing set anomaly ratio\",testinganomaly)\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "}\n",
    "\n",
    "%%\n",
    "///test best config\n",
    "myMap := make(map[config][]float64)\n",
    "myMap[config{10, 50}] = []float64{0.5663299756015053, 0.5784793547873575, 0.602391343317249, 0.6939057554846884, 0.5689573648735637}\n",
    "myMap[config{10, 100}] = []float64{0.7276119962614284, 0.7033651350563244, 0.6943534857604245, 0.7365462700324026, 0.7053684071844848}\n",
    "myMap[config{20, 50}] = []float64{0.5864679952729727, 0.6908322825748243, 0.6938493643294152, 0.6978173332046268, 0.6560886870122624}\n",
    "myMap[config{20, 100}] = []float64{0.7354727967361132, 0.7005686557080835, 0.715626945402174, 0.7171468309980348, 0.6951911213811953}\n",
    "\n",
    "bestConfig:=findBestConfig(myMap)\n",
    "fmt.Println(bestConfig)\n",
    "\n",
    "\n",
    "///test Kfold\n",
    "\n",
    "TestStratifiedKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk Code :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func KFold(K int, datasetlen int)(ch chan Split){\n",
    "\n",
    "\tKpoint :=  int(math.Ceil(float64(datasetlen)/float64(K)))\n",
    "\tKpoints:=[]int{0}\n",
    "\n",
    "\tfor j:=1; j< K; j++{\n",
    "\t\tif Kpoints[j-1] + Kpoint >= datasetlen {\n",
    "\t\t\tbreak\n",
    "\t\t} \n",
    "\t\tKpoints = append(Kpoints, Kpoints[j-1] + Kpoint)\n",
    "\t\t\n",
    "\t}\n",
    "\tKpoints = append(Kpoints, datasetlen)\n",
    "\n",
    "    Indexes:=make([]int, datasetlen)\n",
    "\tfor i:=0; i<datasetlen; i++{\n",
    "\t\tIndexes[i]=i\n",
    "\t\t\n",
    "\t} \n",
    "\n",
    "\tch = make(chan Split)\n",
    "\t\n",
    "\tgo func(){\n",
    "\t\tvar sp *Split\n",
    "\t\tfor testsplit:=0; testsplit<K; testsplit++{\n",
    "\t\t\tif testsplit == 0{\n",
    "\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[:Kpoints[1]],\n",
    "\t\t\t\t\tTrainIndex:  Indexes[Kpoints[1]:],\t\t\t\t\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t}else if testsplit == K-1{\n",
    "\t\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[Kpoints[K-1]:],\n",
    "\t\t\t\t\tTrainIndex:  Indexes[:Kpoints[K-1]],\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\t\tbefore:= Indexes[:Kpoints[testsplit]]\n",
    "\t\t\t\t\tafter:= Indexes[Kpoints[testsplit+1]:]\n",
    "\t\t\t\t\tconcatenated:=make([]int, len(before)+len(after))\n",
    "\t\t\t\t\tcopy(concatenated, before)\n",
    "    \t\t\t\tcopy(concatenated[len(before):], after)\n",
    "\n",
    "\t\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[Kpoints[testsplit]:Kpoints[testsplit+1]],\n",
    "\t\t\t\t\tTrainIndex:  concatenated,\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\tch <-*sp\n",
    "\t\t}\n",
    "\t\tclose(ch)\n",
    "\t}()\n",
    "\treturn ch\n",
    "\n",
    "}\n",
    "func getElements(indexTrain []int ,indexTest []int ,dataArray [][]float64, labelsArray []int)([][]float64,[][]float64, []int) {\n",
    "\tdataTrain := make([][]float64, len(indexTrain))\n",
    "\tdataTest := make([][]float64, len(indexTest))\n",
    "\tlabels := make([]int, len(indexTest))\n",
    "\t\n",
    "\tfor i, index := range indexTrain {\n",
    "\t\tdataTrain[i] = dataArray[index]\n",
    "\t}\n",
    "\tfor i, index := range indexTest {\n",
    "\t\tdataTest[i] = dataArray[index]\n",
    "\t\tlabels[i] = labelsArray[index]\n",
    "\n",
    "\t}\n",
    "\treturn dataTrain,dataTest,labels\n",
    "}\n",
    "\n",
    " func CrossValidation(dataset string){\n",
    "\t\n",
    "\ti:=1\n",
    "\tdata:=loadData(dataset)\n",
    "\tlabels:=LoadLabels(\"training_labels.csv\")\n",
    "\tfor s := range KFold(5,len(data)){\n",
    "\t\tfmt.Println(\"%Iteration N.\",i)\n",
    "\t\ti++\n",
    "\t\ttraindata,testdata,labeldata := getElements(s.TrainIndex,s.TestIndex,data,labels)\n",
    "\t\tforest:=isoForestTrain_Test(traindata, testdata,100,1000,0.8)\n",
    "\t\tAccuracyScore(forest.Labels,labeldata)\n",
    "\t\tF1Score(forest.Labels,labeldata)\t\n",
    "\t}\n",
    "\n",
    "}\n",
    "%%\n",
    "/* data := loadData(\"training.csv\")\n",
    "fmt.Println(data)\n",
    "//datasetlen:=len(data)\n",
    "for s := range KFold(5,data){\n",
    "\tfmt.Println(s.TrainData)\n",
    "\t\n",
    "} */\n",
    "\n",
    "cache.ResetKey(\"my_forest\")\n",
    "var forest = cache.Cache(\"my_forest\", func() * iforest.Forest {return isoForestTrain_Test(data,data,configuration.treeNum,configuration.subsamplesize,outlier)})\n",
    "\n",
    "///////////////////////\n",
    "\n",
    "\n",
    "type config struct{\n",
    "\ttreeNum int\n",
    "\tsubsamplesize int\n",
    "}\n",
    "\n",
    "func CrossValidation(data map[int][][]float64,treenummax int,subsamplmax int,anomaly float64) *config{\n",
    "\n",
    "\tmeanF1Arr := make([]float64,0)\n",
    "\tconfigArr := make([]config,0)\n",
    "\ttreenumStep := 10\n",
    "\n",
    "\tfor tr_n :=10 ;tr_n <=treenummax; tr_n+= treenumStep{\n",
    "\t\tfor sss := 50; sss<=subsamplmax; sss+= 50{\n",
    "\t\t\tvar conf *config\n",
    "\t\t\tfmt.Println(\"Tree number = \",tr_n)\n",
    "\t\t\tfmt.Println(\"Subsamplingsize = \",sss)\n",
    "\t\t\t//Acc_arr:=make([]float64,0)\n",
    "\t\t\tF1_arr:=make([]float64,0)\n",
    "\t\t\tfor s := range StratifiedKFold(5,data){\n",
    "\t\t\t\t\tforest:=isoForestTrain_Test(s.TrainData, s.ValidateData,tr_n,sss,anomaly)\n",
    "\t\t\t\t\t//Acc_arr = append(Acc_arr,AccuracyScore(forest.Labels,s.LabelData))\n",
    "\t\t\t\t\tF1_arr = append(F1_arr,F1Score(forest.Labels,s.LabelData))\n",
    "\t\t\t\t}\n",
    "\t\t\t\t\t\n",
    "\t\t\tmean_f1:= Mean(F1_arr)\n",
    "\t\t\tfmt.Println(\"Configuration Mean F1 Score is \",mean_f1)\n",
    "\t\t    meanF1Arr = append(meanF1Arr,mean_f1)\n",
    "\n",
    "\t\t    conf = &config{\n",
    "\t\t\t\ttreeNum:tr_n,\n",
    "\t\t\t\tsubsamplesize:sss,\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tconfigArr = append(configArr,*conf)\n",
    "\t\t}\n",
    "\t\tif tr_n == 100{\n",
    "\t\t\ttreenumStep = 100\n",
    "\t\t}else if tr_n == 1000{\n",
    "\t\t\ttreenumStep = 500\n",
    "\t\t}\n",
    "\t}\n",
    "\tmaxIndex := findMaxIndex(meanF1Arr)\n",
    "\tbestConfig := configArr[maxIndex]\n",
    "\treturn &bestConfig\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.21.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
