{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\t\"github.com/pa-m/sklearn/metrics\"\n",
    "\t    ms \"github.com/pa-m/sklearn/model_selection\"\n",
    "\t\t\"github.com/e-XpertSolutions/go-iforest/iforest\"\t\n",
    "\t\t\"bufio\"\n",
    "\t\t\"encoding/csv\"\n",
    "\t\t\"strconv\"\n",
    "\t\t\"github.com/janpfeifer/gonb/gonbui\"\n",
    "\t\t\"gonum.org/v1/plot/plotutil\"\n",
    "\t\t\"gonum.org/v1/plot\"\n",
    "\t\t\"gonum.org/v1/plot/plotter\"\n",
    "\t\t\"gonum.org/v1/plot/vg\"\n",
    "\t\t\"gonum.org/v1/plot/vg/draw\"\n",
    "\t\t\"os/exec\"\n",
    "\t\t\"github.com/janpfeifer/gonb/cache\"\n",
    "\t\t\"math\"\n",
    "\t\t\"math/rand\"\n",
    "\n",
    "\t)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Split struct{\n",
    "\tTrainData [][] float64\n",
    "\tValidateData [][] float64\n",
    "\tLabelData []int\n",
    "\t//trainLabelData []int for unit testing\n",
    "\t}\n",
    "\n",
    "type config struct{\n",
    "\ttreeNum int\n",
    "\tsubsamplesize int\n",
    "}\n",
    "\n",
    "//load file Data and Return [][]float64 array\n",
    "func loadData(myfile string) [][]float64 {\n",
    "\n",
    "\tl:=false\n",
    "file, err := os.Open(myfile)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error opening file:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\n",
    "\treader := csv.NewReader(file)\n",
    "\trecords, err := reader.ReadAll()\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error reading CSV:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\t\n",
    "\tinputData := make([][]float64, len(records))\n",
    "\tfor i, row := range records {\n",
    "\n",
    "\t\tinputData[i] = make([]float64, len(row))\n",
    "\t\tfor j, value := range row {\n",
    "\t\t\tinputData[i][j], err = strconv.ParseFloat(value, 64)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tfmt.Printf(\"Error converting to float: line %d\",i)\n",
    "\t\t\t\tl=true\n",
    "\t\t\t\tbreak\t\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tif l == true{\n",
    "\t\t\tbreak\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn inputData\n",
    "}\n",
    "\n",
    "func LoadLabels(filePath string)[]int{\n",
    "\tfile, err := os.Open(filePath)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"Error opening file:\", err)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\n",
    "\tscanner := bufio.NewScanner(file)\n",
    "\t\n",
    "\tvar labels []int\n",
    "\n",
    "\tfor scanner.Scan() {\n",
    "\t\tlabel,err := strconv.Atoi(scanner.Text())\n",
    "\t\tif err != nil {\n",
    "\t\t\t// Handle the error if the conversion fails\n",
    "\t\t\tfmt.Println(\"Error:\", err)\n",
    "\t\t\treturn nil\n",
    "\t\t}\n",
    "\t\tlabels= append(labels,label)\n",
    "\t}\n",
    "\treturn labels\n",
    "}\n",
    "\n",
    "//Convert labels to float for F1 and Accuracy Score metrics\n",
    "func ConvertToFloat(Labels_Pred []int , labels_Tru []int)([]float64 ,[]float64){\n",
    "\n",
    "\tlength :=len(Labels_Pred)\n",
    "\tlabelsPred_float := make([]float64, length)\n",
    "\tlabelsTru_float := make([]float64, length)\n",
    "\n",
    "\tfor i:=0; i<length; i++ {\n",
    "\t\t\n",
    "\t\tlabelsPred_float[i] = float64(Labels_Pred[i])\n",
    "\t\tlabelsTru_float[i] = float64(labels_Tru[i])\n",
    "\t\t\n",
    "\t}\n",
    "\treturn labelsPred_float,labelsTru_float\n",
    "\n",
    "}\n",
    "\n",
    "func F1Score(labelsPred []int, labelsTru []int) float64{\n",
    "\n",
    "\tpred,tru := ConvertToFloat(labelsPred,labelsTru)\n",
    "\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\tvar sampleWeight []float64\n",
    "\t/* fmt.Printf(\"F1 macro %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"macro\", sampleWeight))\n",
    "\tfmt.Printf(\"F1 micro %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"micro\", sampleWeight))\n",
    "\tfmt.Printf(\"F1 weighted %.2f\\n\", metrics.F1Score(Ytrue, Ypred, \"weighted\", sampleWeight)) */\n",
    "\treturn metrics.F1Score(Ytrue, Ypred, \"weighted\", sampleWeight)\n",
    "\n",
    "}\n",
    "\n",
    "func AccuracyScore(labelsPred []int, labelsTru []int)float64{\n",
    "\n",
    "\tpred,tru := ConvertToFloat(labelsPred,labelsTru)\n",
    "\n",
    "\tvar nilDense *mat.Dense\n",
    "\tnormalize, sampleWeight := true, nilDense\n",
    "\tYpred, Ytrue := mat.NewDense(len(pred), 1, pred), mat.NewDense(len(tru), 1, tru)\n",
    "\treturn metrics.AccuracyScore(Ytrue, Ypred, normalize, sampleWeight)\n",
    "\n",
    "}\n",
    "\n",
    "// call command line executable\n",
    "func prepareDataset(dataset string){\n",
    "\tcmd :=exec.Command(\"./extract_splitDataset.sh\", dataset)\n",
    "\tcmd.Run()\n",
    "}\n",
    "\n",
    "func Mean(array []float64)float64{\n",
    "\tsum := 0.0\n",
    "    for _, num := range array {\n",
    "        sum += num\n",
    "    }\n",
    "\n",
    "    // Calculate the mean\n",
    "    mean := sum / float64(len(array))\n",
    "\treturn mean\n",
    "}\n",
    "\n",
    "func outlierRatio(lab []int) float64{\n",
    "\tcount :=0 \n",
    "\tfor _,v := range lab{\n",
    "\t\tif v == 1{\n",
    "\t\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\tanomaly := float64(count)/float64(len(lab))\n",
    "\treturn anomaly\n",
    "}\n",
    "\n",
    "func findMaxIndex(arr []float64)int{\n",
    "\n",
    "\tmaxIndex := 0 \n",
    "\n",
    "    for i := 1; i < len(arr); i++ {\n",
    "     \n",
    "        if arr[i] > arr[maxIndex] {\n",
    "            maxIndex = i\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return maxIndex \n",
    "}\n",
    "\n",
    "\n",
    "func BuildLabelsArray(lendata int, lenzerodata int)[]int{\n",
    "\n",
    "\n",
    "labeldata := make([]int, lendata)\n",
    "\t\t\tfor i:=0; i<lendata; i++{\n",
    "\t\t\t\tif i < lenzerodata{\n",
    "\t\t\t\tlabeldata[i] = 0\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\tlabeldata[i] = 1\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\treturn labeldata\n",
    "}\n",
    "\n",
    "func findBestConfig(themap map[config][]float64)*config{\n",
    "\t\n",
    "\thighest_mean := 0.0\n",
    "\tvar bestconf *config\n",
    "\tfor conf,f1s := range themap{\n",
    "\t\tmean := Mean(f1s)\t\n",
    "\t\t\n",
    "\t\tif mean > highest_mean{\n",
    "\t\t\thighest_mean = mean\n",
    "\t\t\tbestconf = &config{\n",
    "                treeNum:       conf.treeNum,\n",
    "                subsamplesize: conf.subsamplesize,\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"Highest mean is: \",highest_mean)\n",
    "\treturn bestconf\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Isolation Forest algorithm\n",
    "\n",
    "func isoForestTrain_Test(training_data [][]float64 ,testing_data [][]float64 , treesNumber int, subsampleSize int, outliers float64) *iforest.Forest{\n",
    "//model initialization\n",
    "forest := iforest.NewForest(treesNumber, subsampleSize, outliers)\n",
    "\n",
    "//training stage - creating trees\n",
    "forest.Train(training_data)\n",
    "\n",
    "//testing stage - finding anomalies \n",
    "forest.Test(testing_data)\n",
    "\n",
    "//threshold := forest.AnomalyBound\n",
    "//labels := forest.Labels\n",
    "\n",
    "//fmt.Println(\"threshold is\",threshold)\n",
    "\n",
    "return forest;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data, K-Fold Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "func SplitDataset (dataset [][]float64, labels[]int, splitRatio float64)(map[int][][]float64,map[int][][]float64,float64){\n",
    "\n",
    "\tmyMap := make(map[int][][]float64)\n",
    "\tTrainingIndex_Data := make(map[int][][]float64)\n",
    "\tTestingIndex_Data := make(map[int][][]float64)\n",
    "\tcount:=0\n",
    "\tfor i,instance:= range dataset{\n",
    "\t\tif labels[i] == 0{\n",
    "\t\tmyMap[0] = append(myMap[0], instance)\n",
    "\t\t}else{\n",
    "\t\tmyMap[1] = append(myMap[1], instance)\n",
    "\t\tcount++\n",
    "\t\t}\n",
    "\t}\n",
    "\tShuffleUnit(myMap)\n",
    "\tsplit0:= int(math.Round(splitRatio * float64(len(myMap[0]))))\n",
    "\tsplit1:= int(math.Round(splitRatio * float64(len(myMap[1]))))\n",
    "\n",
    "\tTrainingIndex_Data[0] = myMap[0][:split0]\n",
    "\tTrainingIndex_Data[1] = myMap[1][:split1]\n",
    "\tTestingIndex_Data[0] = myMap[0][split0:]\n",
    "\tTestingIndex_Data[1] = myMap[1][split1:] \n",
    "\n",
    "\tanomaly := float64(count)/float64(len(labels))\n",
    "\treturn  TrainingIndex_Data, TestingIndex_Data, anomaly\n",
    "}\n",
    "\n",
    "func Shuffle(testing_set [][]float64, training_set [][]float64, label_set []int){\n",
    "\n",
    "\trand.Shuffle(len(training_set), func(i, j int) {\n",
    "\t\ttraining_set[i], training_set[j] = training_set[j], training_set[i]\n",
    "\t})\n",
    "\trand.Shuffle(len(testing_set), func(i, j int) {\n",
    "\t\ttesting_set[i], testing_set[j] = testing_set[j], testing_set[i]\n",
    "\t\tlabel_set [i], label_set[j] = label_set[j], label_set[i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func ShuffleUnit(data_label map[int][][]float64){\n",
    "\n",
    "\trand.Shuffle(len(data_label[0]), func(i, j int) {\n",
    "\t\tdata_label[0][i], data_label[0][j] = data_label[0][j], data_label[0][i]\n",
    "\t})\n",
    "\trand.Shuffle(len(data_label[1]), func(i, j int) {\n",
    "\t\tdata_label[1][i], data_label[1][j] = data_label[1][j], data_label[1][i]\n",
    "\t})\n",
    "}\n",
    "\n",
    "func StratifiedKFold(K int, data_label map[int][][]float64)(ch chan Split){\n",
    "\n",
    "\n",
    "\tfoldSizezeros:= int(math.Round(float64((len(data_label[0])/K))))\n",
    "\tfoldSizeones:= int(math.Round((float64(len(data_label[1])/K))))\n",
    "\n",
    "\tch = make(chan Split)\n",
    "\t\n",
    "\tgo func(){\n",
    "\t\t\n",
    "\t\tvar sp *Split\n",
    "\t\tfor i:=0; i<K; i++{\n",
    "\t\t\tstartIndex0 := i * foldSizezeros\n",
    "\t\t\tendIndex0 := (i + 1) * foldSizezeros\n",
    "\t\t\tstartIndex1 := i * foldSizeones\n",
    "\t\t\tendIndex1 := (i + 1) * foldSizeones\n",
    "\n",
    "\t\t\tif i == K-1 {\n",
    "\t\t\t\tendIndex0 = len(data_label[0])\n",
    "\t\t\t\tendIndex1 = len(data_label[1])\n",
    "\t\t\t}\n",
    "\t\t\ttrainData0 := make([][]float64, 0)\n",
    "\t\t\ttrainData1 := make([][]float64, 0)\n",
    "\n",
    "\t\t\t// Merge all data except the test data into the training data\n",
    "\t\t\ttrainData0 = append(trainData0, data_label[0][:startIndex0]...)\n",
    "\t\t\ttrainData0 = append(trainData0, data_label[0][endIndex0:]...)\n",
    "\t\t\ttrainData1 = append(trainData1, data_label[1][:startIndex1]...)\n",
    "\t\t\ttrainData1 = append(trainData1, data_label[1][endIndex1:]...)\n",
    "\t\t\t\n",
    "\t\t\ttrainData := Merge(trainData0,trainData1)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\tvalidData0:=data_label[0][startIndex0:endIndex0]\n",
    "\t\t\tvalidData1:=data_label[1][startIndex1:endIndex1]\n",
    "\t\t\t\n",
    "\t\t\tvalidData := Merge(validData0, validData1)\n",
    "\n",
    "\t\t\tvalidDatalen:= len(validData)\n",
    "\t\t\n",
    "\t\t    labeldata:= BuildLabelsArray(validDatalen,len(validData0))\n",
    "\t\t\t\n",
    "\t\t\tShuffle(validData,trainData,labeldata)\n",
    "\t\t\t\n",
    "\t\t\tsp = &Split{\n",
    "\t\t\t\tTrainData: trainData,\n",
    "\t\t\t\tValidateData:  validData,\n",
    "\t\t\t\tLabelData: labeldata,\n",
    "\t\t\t\t//trainLabelData: trainlabeldata,\n",
    "\t\t\t}\n",
    "\t\t\tch <- *sp\n",
    "\t\t}\n",
    "\t\tclose(ch)\t\n",
    "\t}()\n",
    "\treturn ch\n",
    "}\n",
    "\n",
    "func Merge(data1 [][]float64, data2 [][]float64)[][]float64{\n",
    "\n",
    "\tconcatenated:=make([][]float64, len(data1)+len(data2))\n",
    "\t\t\t\t\tcopy(concatenated, data1)\n",
    "    \t\t\t\tcopy(concatenated[len(data1):], data2)\n",
    "\treturn concatenated\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func GridSearchCV(data map[int][][]float64,treenummax int,subsamplmax int,anomaly float64) *config{\n",
    "\n",
    "\tConfF1s := make(map[config][]float64,0)\n",
    "\tvar conf config\n",
    "\ti := 1\n",
    "\t\n",
    "\tfor s := range StratifiedKFold(5,data){\t\n",
    "\t\ttreenumStep := 10\n",
    "\t\tfmt.Println(\"Entering Iteration num \",i)\n",
    "\t\tfor tr_n :=10 ;tr_n <=treenummax; tr_n+= treenumStep{\n",
    "\t\t\tfor sss := 50; sss<=subsamplmax; sss+= 50{\n",
    "\t\t\t\tconf = config{\n",
    "\t\t\t\t\ttreeNum:tr_n,\n",
    "\t\t\t\t\tsubsamplesize:sss,\n",
    "\t\t\t\t}\n",
    "\t\t\t\tforest:=isoForestTrain_Test(s.TrainData, s.ValidateData,tr_n,sss,anomaly)\n",
    "\t\t\t\tf1Score := F1Score(forest.Labels,s.LabelData)\n",
    "\t\t\t\tConfF1s[conf] = append(ConfF1s[conf],f1Score)\n",
    "\t\t\t}\n",
    "\t\t\tif tr_n == 100{\n",
    "\t\t\t\ttreenumStep = 100\n",
    "\t\t\t}else if tr_n == 1000{\n",
    "\t\t\t\ttreenumStep = 500\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\ti++\n",
    "\t}\n",
    "\tbestConfig:=findBestConfig(ConfF1s)\n",
    "\tfmt.Println(ConfF1s)\n",
    "\t\n",
    "\treturn bestConfig\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly ratio is:  0.07193103596551799\n",
      "Entering Iteration num  1\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "Entering Iteration num  2\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "Entering Iteration num  3\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "Entering Iteration num  4\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "Entering Iteration num  5\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "6.978071926021253\n",
      "8.364671030069179\n",
      "9.175657275024252\n",
      "9.751040979248984\n",
      "10.197337122729415\n",
      "10.561985143248037\n",
      "10.870289459919139\n",
      "Highest mean is:  0.7124137435571408\n",
      "map[{10 50}:[0.6176314966448795 0.7293309842548589 0.7080544292845883 0.5776772769265917 0.7120336433171897] {10 100}:[0.656013603161053 0.6515363964440836 0.7489063353298916 0.6078912004021924 0.6666221780518459] {10 150}:[0.7181094309530962 0.6724407755967844 0.6956483039949048 0.6793554882963104 0.6842800510167065] {10 200}:[0.7121859577060896 0.6857132058158077 0.6743231711388942 0.7078730311171706 0.6856337973904704] {10 250}:[0.6787094862707637 0.7151756201958857 0.6691825147355117 0.6117456806483155 0.6605314170649076] {10 300}:[0.7136547012860731 0.5975456764646067 0.5991568160691605 0.7175864108212306 0.6519572053309002] {10 350}:[0.6880397236990331 0.6066459971548879 0.6964211268610303 0.6958892951931254 0.6531097186686482] {20 50}:[0.7188590013330263 0.621256038647343 0.6978779718384163 0.6999555583711763 0.691679741925865] {20 100}:[0.711296185971706 0.6684388193668349 0.7075980058576785 0.7437452836693905 0.67736242900943] {20 150}:[0.7185815789306715 0.6639638737079736 0.7094886227998968 0.6925287128983968 0.7126408269013551] {20 200}:[0.7060707895817184 0.6941803612580686 0.6965908019823662 0.6947892256844727 0.6855439606649457] {20 250}:[0.6871932313756546 0.7173991479750229 0.653665758793091 0.6373047424238182 0.6987682005030034] {20 300}:[0.6910966325640754 0.7204948238502676 0.718647441346502 0.7083177400674769 0.696287034653457] {20 350}:[0.7067200172911404 0.7203716931942021 0.7167331522484582 0.69800146252381 0.6907468967111239] {30 50}:[0.6491314064976466 0.7219939430439083 0.6818576471744524 0.5838001362111181 0.7193254219734755] {30 100}:[0.7248951900618951 0.6826289302770503 0.7241585425459396 0.6876325144825814 0.7283359019401356] {30 150}:[0.7043153595147197 0.6956713799818819 0.6942643196962195 0.6945136461781882 0.6917451778988226] {30 200}:[0.6916089163035328 0.7019093226597066 0.7126660104711502 0.6877860887920164 0.7082826431184363] {30 250}:[0.6946530004095572 0.6912151427604674 0.7086688260808767 0.687541051964184 0.6684014417083107] {30 300}:[0.6956318321166322 0.6256186783593112 0.7193886523566828 0.7136193644029583 0.7014130484706149] {30 350}:[0.6297344364816734 0.6711026226471021 0.6933146644281938 0.6952339346347791 0.6852360376029891] {40 50}:[0.6678024141211443 0.6641277138475601 0.6808782131186848 0.6465306394155615 0.6705735959538841] {40 100}:[0.7037536218932801 0.7278183917605284 0.6613719345860835 0.6870239531979947 0.7429918222201413] {40 150}:[0.6967431536742728 0.6959595123958053 0.7156965521833334 0.690482570586769 0.6923316235906745] {40 200}:[0.7178906853661772 0.7173115802078136 0.7198801727754425 0.6935130328967989 0.6816171202464736] {40 250}:[0.7030405111325437 0.6708370745090819 0.7025184208456623 0.7111600169521234 0.7040749009223223] {40 300}:[0.6985341431607369 0.7049473143388392 0.7023726835739077 0.7029812326638005 0.6893356896096631] {40 350}:[0.6863548965549924 0.7064452813293449 0.7107578432968791 0.6798095557794162 0.6622011023807178] {50 50}:[0.691116073753099 0.7201437308014675 0.6948115748686194 0.7420219973538542 0.6825103973300737] {50 100}:[0.7062023088226379 0.6969594442760412 0.6884930831775037 0.6976438957338515 0.7129639775785432] {50 150}:[0.7310915194700083 0.723444005460188 0.6982355245563434 0.7032444520525577 0.6720850384541438] {50 200}:[0.7021911729061574 0.7185226401902967 0.7010151509887619 0.6917002596721636 0.7060005723790386] {50 250}:[0.697983707306201 0.6904716804890338 0.6855907721333989 0.6983170584753993 0.6887255961499388] {50 300}:[0.7127648295705407 0.7085520611798117 0.7150585915247524 0.6986334300116501 0.7014421744020507] {50 350}:[0.7019337046703708 0.6970595819044578 0.6865324229296745 0.7046956366542646 0.7067261501400647] {60 50}:[0.648099437187694 0.7319575316363942 0.6599897884403896 0.7073343773602192 0.7134548886757177] {60 100}:[0.7060005723790386 0.6960063238642585 0.6957422729248924 0.7130456983812604 0.713870868329573] {60 150}:[0.7083762698076383 0.6918456310681822 0.6835544732556803 0.7130405547566576 0.702208843434321] {60 200}:[0.7061994492836887 0.7179609025688571 0.7051111544784258 0.7009917452545352 0.7086108607223629] {60 250}:[0.6966382786883781 0.6978787826023907 0.7010208627434905 0.6936189389731402 0.6796191229534102] {60 300}:[0.706304846923985 0.6951871231663258 0.7112902683142617 0.6976681309943509 0.6977149424628041] {60 350}:[0.706304846923985 0.6811320324893951 0.7162583010614134 0.6974163074424766 0.6886857936289815] {70 50}:[0.6796283281733617 0.7290380880377358 0.666956705868368 0.6872759849977178 0.6063857675104124] {70 100}:[0.7043387652489463 0.6762986956454186 0.709113535031183 0.6910443082082086 0.7037593885241311] {70 150}:[0.7022322491685478 0.7044791996543062 0.7089496948915965 0.6946655444219534 0.7264414781612962] {70 200}:[0.706843178811198 0.6945317626079796 0.7173055420105109 0.6863631613628784 0.7114307027196215] {70 250}:[0.6959678401613032 0.7098157070579826 0.6942040823288065 0.6947948126781027 0.6896399641546096] {70 300}:[0.7224313978061474 0.7014832656732949 0.7093709981076762 0.7059537609105853 0.7000789216196959] {70 350}:[0.7121272718826626 0.7000087044170159 0.7030982613349338 0.7024539375448435 0.7083411458017036] {80 50}:[0.6687969910543883 0.6646834520233118 0.6500234357624055 0.6786626748023104 0.6885375387384489] {80 100}:[0.7121219566863873 0.7057899207709987 0.6893878521269308 0.6931329722471158 0.6966850901568316] {80 150}:[0.6923784350591277 0.7046898512623461 0.699798052808976 0.7027237695873074 0.7074807657110609] {80 200}:[0.7034727530825602 0.7197842409376424 0.6930337956174739 0.6916413131810106 0.6941037730291154] {80 250}:[0.6988852291741366 0.697457479386311 0.7027237695873074 0.6943021849182773 0.6986043603634169] {80 300}:[0.6988150119714567 0.691418799955835 0.6887326060354884 0.6906230049921289 0.7030982613349338] {80 350}:[0.697457479386311 0.705766515036772 0.695982918130032 0.7177020583672903 0.6997044298720694] {90 50}:[0.697442373266459 0.7084289435464801 0.6805042238941662 0.6791752358285934 0.6792244124237499] {90 100}:[0.7056084785811447 0.6857511956588833 0.7058739203375664 0.6964042213461116 0.7150351857905257] {90 150}:[0.7131861327866204 0.7115477313907548 0.7108455593639552 0.7160416323622717 0.7104476618821022] {90 200}:[0.7046196340596661 0.712600989430954 0.7163459069072182 0.6950054685073828 0.6974808851205376] {90 250}:[0.6911379311451152 0.7021386262316411 0.7123669320886875 0.7073697828987155 0.7017407287497881] {90 300}:[0.7034259416141069 0.6980192170077506 0.689111064789007 0.7162054725018583 0.6964276270803382] {90 350}:[0.7058133265052253 0.7021152204974145 0.7101433873371557 0.6939633301809061 0.6984171144896036] {100 50}:[0.7041749251093596 0.7200388856651287 0.6987731281152304 0.7005749551560041 0.7152692431327923] {100 100}:[0.721120676689455 0.7072878877615043 0.6980426227419773 0.7174927878843241 0.7169076445286579] {100 150}:[0.7094880267788095 0.7055340467431707 0.7066657245163506 0.7092071579680896 0.710588096287462] {100 200}:[0.701810945952468 0.687349985287413 0.698323491552697 0.7164575930357876 0.703355724411427] {100 250}:[0.6964978442830182 0.709722084121076 0.7065154985320248 0.7025188597517041 0.6927584729950623] {100 300}:[0.6858950466783453 0.7069192259633317 0.7133031614577535 0.708107088459437 0.7001257330881491] {100 350}:[0.70857520314397 0.6986511718318702 0.6956786435850855 0.7116881657961147 0.7085517974097435] {200 50}:[0.7034961588167868 0.6983344384538095 0.6904123533840891 0.6876504767453442 0.7052749946180124] {200 100}:[0.6923605675397556 0.7022671283371988 0.7020684090289612 0.6974808851205376 0.6938819707512226] {200 150}:[0.6972936392467244 0.7115477313907548 0.7148011284482592 0.6996810241378428 0.7164161241098982] {200 200}:[0.7070772361534645 0.6932678529597405 0.7009215280518553 0.6995171839982562 0.69893204064259] {200 250}:[0.6984171144896036 0.7005470363042289 0.6940636479234465 0.6965914672199248 0.6906698164605822] {200 300}:[0.7051111544784258 0.6981830571473371 0.7065623100004781 0.7013662370021616 0.706304846923985] {200 350}:[0.7052047774153324 0.696451032814565 0.707170859090371 0.6843736739536131 0.6940870536576732] {300 50}:[0.6890767103067856 0.696848930296418 0.6917487126314352 0.6869248989843181 0.7073141999817515] {300 100}:[0.7053218060864657 0.6973638564494044 0.7023726835739077 0.7003597904304155 0.6979724055392973] {300 150}:[0.6972234220440444 0.7128528932650781 0.7171885133393776 0.7071474533561444 0.7023492778396809] {300 200}:[0.7004300076330956 0.7085986088781967 0.7046664455281194 0.7120392518095144 0.6993065323902163] {300 250}:[0.6956786435850855 0.7092071579680896 0.70878585475201 0.7050643430099724 0.7108689650981819] {300 300}:[0.6988384177056833 0.7100088447927723 0.7006172535069087 0.7057957282071715 0.6990256635794966] {300 350}:[0.7000605724913164 0.7070772361534645 0.706164412518625 0.7013662370021616 0.7005704420384555] {400 50}:[0.6800828953495378 0.7015768886102015 0.6959595123958053 0.6746134827810997 0.6834608503187737] {400 100}:[0.7008981223176286 0.7014364542048416 0.7013194255337083 0.7037536218932801 0.7105412848190087] {400 150}:[0.7024481966069668 0.7069602074823312 0.7058133265052253 0.702957826929574 0.704432388185853] {400 200}:[0.7021152204974145 0.7023492778396809 0.706772961608518 0.7045026053885328 0.7035429702852402] {400 250}:[0.6969659589675512 0.6983000858184704 0.6990490693137232 0.7052047774153324 0.7090901292969565] {400 300}:[0.7057197035683187 0.7080836827252104 0.7100731701344758 0.7019045688893746 0.7091603464996364] {400 350}:[0.7021854377000945 0.7100322509960256 0.7045494168569861 0.7018577574209213 0.700266167493509] {500 50}:[0.694765819950246 0.7027471753215341 0.6860120753494787 0.6961935697380718 0.6961935697380718] {500 100}:[0.7065623100004781 0.7033791301456536 0.7057431093025454 0.7021152204974145 0.7151522144616589] {500 150}:[0.706375064126665 0.7099336639751189 0.7029110154611206 0.7045260111227596 0.7081538999278905] {500 200}:[0.7024897122450409 0.7042451423120397 0.7006640649753622 0.6995874012009362 0.704291953780493] {500 250}:[0.701342831267935 0.7046196340596661 0.7112668625800349 0.7021152204974145 0.6987213890345501] {500 300}:[0.7097454898553026 0.7127239643701594 0.7006874707095888 0.706942632166585 0.707241076293051] {500 350}:[0.7063282526582115 0.7085049859412902 0.7083879572701569 0.7037770276275066 0.7053452118206922] {600 50}:[0.6921911891853145 0.699400155327123 0.6978319711339374 0.6888441691909034 0.7025833351819475] {600 100}:[0.6985809546291901 0.7027471753215341 0.706234629721305 0.706164412518625 0.7047834741992527] {600 150}:[0.7025131179792675 0.7032152900060671 0.7034727530825602 0.7001491388223757 0.7086688260808767] {600 200}:[0.7029110154611206 0.7033791301456536 0.7070304246850111 0.7032621014745204 0.7076623795091307] {600 250}:[0.7047132569965728 0.7082007113963437 0.7038472448301867 0.707170859090371 0.7023664939321053] {600 300}:[0.7084581744728369 0.7102136045398357 0.7086688260808767 0.7009917452545352 0.7030982613349338] {600 350}:[0.7057431093025454 0.7008981223176286 0.707241076293051 0.7016996426378374 0.7009215280518553] {700 50}:[0.6997746470747493 0.6973404507151777 0.7036928609826929 0.6949296600898326 0.6952573403690058] {700 100}:[0.7036365932221468 0.7091603464996364 0.7028407982584406 0.7075277872479184 0.7002427617592824] {700 150}:[0.6981637296668572 0.7104242561478755 0.7063516583924383 0.7040578964382265 0.7054328294513451] {700 200}:[0.6978787826023907 0.7069602074823312 0.7078262196487173 0.701132179659895 0.706304846923985] {700 250}:[0.7045260111227596 0.7026301466504008 0.7071240476219177 0.7005704420384555 0.7019747860920545] {700 300}:[0.7075687565722242 0.7041749251093596 0.7064218755951182 0.7030514498664805 0.702208843434321] {700 350}:[0.700195950290829 0.7032152900060671 0.7046898512623461 0.7017875402182414 0.7018343516866946] {800 50}:[0.6971046475193423 0.6890548207989432 0.7008513108491753 0.6977383481970307 0.7017173230155613] {800 100}:[0.7072176705588243 0.7065154985320248 0.6990256635794966 0.7049941258072925 0.706772961608518] {800 150}:[0.7051579659468791 0.7026531243715348 0.7045962283254394 0.7058601379736786 0.7027237695873074] {800 200}:[0.7033089129429736 0.7004300076330956 0.7034727530825602 0.7030046383980272 0.7021620319658678] {800 250}:[0.7061878182528517 0.7081538999278905 0.7032152900060671 0.7005704420384555 0.6982766800842437] {800 300}:[0.7037536218932801 0.7063282526582115 0.7034259416141069 0.7056494863656387 0.7034025358798802] {800 350}:[0.7041281136409064 0.7046196340596661 0.7090199120942765 0.7033323186772003 0.7040110849697732] {900 50}:[0.6933848816308736 0.6934619071397327 0.694976471558286 0.6894427770405607 0.6881654028983305] {900 100}:[0.7037536218932801 0.7069133960138778 0.7051579659468791 0.7035663760194668 0.6966850901568316] {900 150}:[0.7049704778067248 0.7111498339089017 0.7106408122806124 0.7043855767173997 0.7032855072087469] {900 200}:[0.6997746470747493 0.7092305637023163 0.704432388185853 0.7031450728033871 0.6997044298720694] {900 250}:[0.6985107374265103 0.7074049164326375 0.7056433051178848 0.7042685480462663 0.6999384872143359] {900 300}:[0.7035897817536935 0.7031216670691605 0.7061176010501717 0.7067261501400647 0.7047600684650259] {900 350}:[0.7038940562986399 0.7063516583924383 0.7068899902796513 0.7035195645510135 0.704432388185853] {1000 50}:[0.6930103898832473 0.6952339346347791 0.6816586087833216 0.6911379311451152 0.6999150814801093] {1000 100}:[0.7063984698608916 0.7061176010501717 0.7054856462260521 0.7011789911283485 0.701132179659895] {1000 150}:[0.7042217365778131 0.7023024663712276 0.7057899207709987 0.7059771666448118 0.7036131874879201] {1000 200}:[0.7011087739256685 0.7070070189507844 0.7033089129429736 0.7064920927977982 0.7017875402182414] {1000 250}:[0.7040578964382265 0.7035663760194668 0.699259720921763 0.7010385567229885 0.7030280441322538] {1000 300}:[0.7070538304192377 0.7022790606370011 0.7062112239870784 0.7017641344840146 0.7044791996543062] {1000 350}:[0.7070070189507844 0.7066325272031581 0.7064920927977982 0.7060239781132651 0.7020684090289612] {1500 50}:[0.7028876097268939 0.6967787130937381 0.7044791996543062 0.7014130484706149 0.6904357591183157] {1500 100}:[0.7013017371825306 0.705368617554919 0.7043855767173997 0.7020918147631878 0.7020450032947345] {1500 150}:[0.7033323186772003 0.7093944038419029 0.7049707200730658 0.7063516583924383 0.702957826929574] {1500 200}:[0.7031216670691605 0.7017875402182414 0.7014364542048416 0.7014130484706149 0.7082943343332503] {1500 250}:[0.705696297834092 0.7043855767173997 0.702957826929574 0.7028757018170128 0.706234629721305] {1500 300}:[0.7047600684650259 0.7075687565722242 0.7040578964382265 0.7049005028703859 0.7024897122450409] {1500 350}:[0.7049941258072925 0.7085049859412902 0.7062580354555317 0.7019513803578279 0.7026067409161741] {2000 50}:[0.6945551683422062 0.7073581049641843 0.6954791933700438 0.7032621014745204 0.7027237695873074] {2000 100}:[0.7045962283254394 0.7077560024460373 0.7000321101512426 0.7025131179792675 0.7055090519602789] {2000 150}:[0.7032855072087469 0.7089731006258231 0.7038296071338911 0.7031684785376138 0.7057899207709987] {2000 200}:[0.7048770971361593 0.7035195645510135 0.7064452813293449 0.699868270011656 0.7033848892720777] {2000 250}:[0.7025833351819475 0.7065623100004781 0.7050877487441991 0.700336384696189 0.7024194950423609] {2000 300}:[0.7040813021724531 0.7029812326638005 0.7044557939200795 0.7012960197994818 0.7056260806314121] {2000 350}:[0.7038706505644132 0.7059537609105853 0.7054154290233723 0.7056026748971854 0.7036599989563734]]\n",
      "Training Model with parameters...  &{90 150}\n",
      "9.175657275024252\n",
      "Predict Accuracy is... 0.9206623016557541\n",
      "Predict F1 is... 0.7017300174643211\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "//load from files the pr \n",
    "data:=loadData(\"dataset.csv\")\n",
    "labels:=LoadLabels(\"labels.csv\")\n",
    "\n",
    "training_data , testing_data , anomaly :=  SplitDataset(data,labels,0.8)\n",
    "fmt.Println(\"anomaly ratio is: \",anomaly)\n",
    "\n",
    "configuration := GridSearchCV(training_data,2000,350,anomaly) //returns the Best configuration {treeNum}{SubsamplingSize}\n",
    "\n",
    "\n",
    "//train with the best conf\n",
    "fmt.Println(\"Training Model with parameters... \",configuration)\n",
    "forestt := isoForestTrain_Test(data,data,configuration.treeNum,configuration.subsamplesize,anomaly)\n",
    "\n",
    "//prepare the testing data for predict\n",
    "testing := Merge(testing_data[0], testing_data[1])\n",
    "\n",
    "testDatalen := len(testing)\n",
    "testData0len :=len(testing_data[0])\n",
    "\n",
    "labeldata:=BuildLabelsArray(testDatalen,testData0len)\n",
    "\n",
    "\n",
    "predictlabels,_,_ :=forestt.Predict(testing)\n",
    "fmt.Println(\"Predict Accuracy is...\",AccuracyScore(predictlabels,labeldata))\n",
    "fmt.Println(\"Predict F1 is...\",F1Score(predictlabels,labeldata))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func dataLabelGenerator(numberofinstances int)([][]float64 ,[]int){\n",
    "\tdata := make([][]float64,0)\n",
    "\tlabels := make([]int,0)\n",
    "\tcount:=0\n",
    "\tfor j:=0; j<numberofinstances; j++{\n",
    "\t\tlabel := rand.Intn(2)\n",
    "\t\tlabels = append(labels,label)\n",
    "\t\tif label == 0 {\n",
    "\t\t\tdata = append(data,[]float64{0.0, 0.0})\n",
    "\t\t}else{\n",
    "\t\t\tdata= append(data,[]float64{1.1,1.1})\n",
    "\t\t\tcount++\n",
    "\t\t}\t\n",
    "\t} \n",
    "\n",
    "\t\n",
    "\treturn data,labels\n",
    "}\n",
    "\n",
    "func TestSplitDataset(ratio float64)(map[int][][]float64,map[int][][]float64, float64){\n",
    "\n",
    "\tdata,labels := dataLabelGenerator(532)\n",
    "\n",
    "\tdata_label_train,data_label_test,anomaly:=SplitDataset(data,labels,ratio)\n",
    "\ttrainlen0:=len(data_label_train[0])\n",
    "\ttrainlen1:=len(data_label_train[1])\n",
    "    testlen0:=len(data_label_test[0])\n",
    "\ttestlen1:=len(data_label_test[1]) \n",
    " \n",
    "    trainlen := trainlen0+trainlen1\n",
    "\ttestlen := testlen0+testlen1 \n",
    "\tright_train_len := int(float64(len(data))*ratio)\n",
    "\tright_test_len := int(float64(len(data))*(1-ratio))\n",
    "\tfmt.Println(\"SPLITDATASET METRICSSSSSSS\")\n",
    "\tfmt.Println(\"train length\",trainlen)\n",
    "\tfmt.Println(\"what train length should be\",right_train_len)\n",
    "\tfmt.Println(\"test length\",testlen)\n",
    "\tfmt.Println(\"what train test should be\",right_test_len)\n",
    "\n",
    "\ttraininganomaly := float64(trainlen1)/float64(trainlen)\n",
    "\ttestinganomaly := float64(testlen1)/float64(testlen)\n",
    "\n",
    "\tfmt.Println(\"real anomaly ratio\",anomaly)\n",
    "\tfmt.Println(\"training set anomaly ratio\",traininganomaly)\n",
    "\tfmt.Println(\"testing set anomaly ratio\",testinganomaly)\n",
    "\n",
    "\treturn \tdata_label_train,data_label_test,anomaly\n",
    "\n",
    "}\n",
    "\n",
    "func TestStratifiedKFold(){\n",
    "\n",
    "\tdata_label_train,_ ,anomaly:= TestSplitDataset(0.8)\n",
    "\tfmt.Println(\"KFOLD METRICSSSSSSS\")\n",
    "\tfor s := range StratifiedKFold(5,data_label_train){\n",
    "\t\ttraindatalen:=len(s.TrainData)\n",
    "\t\ttestdatalen:=len(s.ValidateData)\n",
    "\t\tvalidatedatalen:=len(s.ValidateData)\n",
    "\t\tKfoldtotallength:= traindatalen+validatedatalen\n",
    "\t\tInitiallen:= len(data_label_train[0])+len(data_label_train[1])\n",
    "\t\tfmt.Println(\"validate data length\",validatedatalen)\n",
    "\t\tfmt.Println(\"traindata length\",traindatalen)\n",
    "\t\tfmt.Println(\"total length length\", Kfoldtotallength)\n",
    "\t\tfmt.Println(\"should be the same as\", Initiallen)\n",
    "\t\tcount:=0\n",
    "\t\t//count1:=0\n",
    "\t\tfor _,v:= range s.LabelData{\n",
    "\t\t\tif v==1{\n",
    "\t\t\t\tcount++\n",
    "\t\t\t} \n",
    "\t\t}\n",
    "\t\t/* for _,v:= range s.trainLabelData{\n",
    "\t\t\tif v==1{\n",
    "\t\t\t\tcount1++\n",
    "\t\t\t} \n",
    "\t\t} */\n",
    "\t\ttestinganomaly:= float64(count)/float64(testdatalen)\n",
    "\t\t//traininganomaly:= float64(count1)/float64(traindatalen)\n",
    "\n",
    "\t\tfmt.Println(\"real anomaly ratio\",anomaly)\n",
    "\t\t//fmt.Println(\"Kfold training set anomaly ratio\",traininganomaly)\n",
    "\t\tfmt.Println(\"Kfold testing set anomaly ratio\",testinganomaly)\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "}\n",
    "\n",
    "%%\n",
    "///test best config\n",
    "myMap := make(map[config][]float64)\n",
    "myMap[config{10, 50}] = []float64{0.5663299756015053, 0.5784793547873575, 0.602391343317249, 0.6939057554846884, 0.5689573648735637}\n",
    "myMap[config{10, 100}] = []float64{0.7276119962614284, 0.7033651350563244, 0.6943534857604245, 0.7365462700324026, 0.7053684071844848}\n",
    "myMap[config{20, 50}] = []float64{0.5864679952729727, 0.6908322825748243, 0.6938493643294152, 0.6978173332046268, 0.6560886870122624}\n",
    "myMap[config{20, 100}] = []float64{0.7354727967361132, 0.7005686557080835, 0.715626945402174, 0.7171468309980348, 0.6951911213811953}\n",
    "\n",
    "bestConfig:=findBestConfig(myMap)\n",
    "fmt.Println(bestConfig)\n",
    "\n",
    "\n",
    "///test Kfold\n",
    "\n",
    "TestStratifiedKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk Code :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func KFold(K int, datasetlen int)(ch chan Split){\n",
    "\n",
    "\tKpoint :=  int(math.Ceil(float64(datasetlen)/float64(K)))\n",
    "\tKpoints:=[]int{0}\n",
    "\n",
    "\tfor j:=1; j< K; j++{\n",
    "\t\tif Kpoints[j-1] + Kpoint >= datasetlen {\n",
    "\t\t\tbreak\n",
    "\t\t} \n",
    "\t\tKpoints = append(Kpoints, Kpoints[j-1] + Kpoint)\n",
    "\t\t\n",
    "\t}\n",
    "\tKpoints = append(Kpoints, datasetlen)\n",
    "\n",
    "    Indexes:=make([]int, datasetlen)\n",
    "\tfor i:=0; i<datasetlen; i++{\n",
    "\t\tIndexes[i]=i\n",
    "\t\t\n",
    "\t} \n",
    "\n",
    "\tch = make(chan Split)\n",
    "\t\n",
    "\tgo func(){\n",
    "\t\tvar sp *Split\n",
    "\t\tfor testsplit:=0; testsplit<K; testsplit++{\n",
    "\t\t\tif testsplit == 0{\n",
    "\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[:Kpoints[1]],\n",
    "\t\t\t\t\tTrainIndex:  Indexes[Kpoints[1]:],\t\t\t\t\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t}else if testsplit == K-1{\n",
    "\t\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[Kpoints[K-1]:],\n",
    "\t\t\t\t\tTrainIndex:  Indexes[:Kpoints[K-1]],\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}else{\n",
    "\t\t\t\t\tbefore:= Indexes[:Kpoints[testsplit]]\n",
    "\t\t\t\t\tafter:= Indexes[Kpoints[testsplit+1]:]\n",
    "\t\t\t\t\tconcatenated:=make([]int, len(before)+len(after))\n",
    "\t\t\t\t\tcopy(concatenated, before)\n",
    "    \t\t\t\tcopy(concatenated[len(before):], after)\n",
    "\n",
    "\t\t\t\t\tsp = &Split{\n",
    "\t\t\t\t\tTestIndex: Indexes[Kpoints[testsplit]:Kpoints[testsplit+1]],\n",
    "\t\t\t\t\tTrainIndex:  concatenated,\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\tch <-*sp\n",
    "\t\t}\n",
    "\t\tclose(ch)\n",
    "\t}()\n",
    "\treturn ch\n",
    "\n",
    "}\n",
    "func getElements(indexTrain []int ,indexTest []int ,dataArray [][]float64, labelsArray []int)([][]float64,[][]float64, []int) {\n",
    "\tdataTrain := make([][]float64, len(indexTrain))\n",
    "\tdataTest := make([][]float64, len(indexTest))\n",
    "\tlabels := make([]int, len(indexTest))\n",
    "\t\n",
    "\tfor i, index := range indexTrain {\n",
    "\t\tdataTrain[i] = dataArray[index]\n",
    "\t}\n",
    "\tfor i, index := range indexTest {\n",
    "\t\tdataTest[i] = dataArray[index]\n",
    "\t\tlabels[i] = labelsArray[index]\n",
    "\n",
    "\t}\n",
    "\treturn dataTrain,dataTest,labels\n",
    "}\n",
    "\n",
    " func CrossValidation(dataset string){\n",
    "\t\n",
    "\ti:=1\n",
    "\tdata:=loadData(dataset)\n",
    "\tlabels:=LoadLabels(\"training_labels.csv\")\n",
    "\tfor s := range KFold(5,len(data)){\n",
    "\t\tfmt.Println(\"%Iteration N.\",i)\n",
    "\t\ti++\n",
    "\t\ttraindata,testdata,labeldata := getElements(s.TrainIndex,s.TestIndex,data,labels)\n",
    "\t\tforest:=isoForestTrain_Test(traindata, testdata,100,1000,0.8)\n",
    "\t\tAccuracyScore(forest.Labels,labeldata)\n",
    "\t\tF1Score(forest.Labels,labeldata)\t\n",
    "\t}\n",
    "\n",
    "}\n",
    "%%\n",
    "/* data := loadData(\"training.csv\")\n",
    "fmt.Println(data)\n",
    "//datasetlen:=len(data)\n",
    "for s := range KFold(5,data){\n",
    "\tfmt.Println(s.TrainData)\n",
    "\t\n",
    "} */\n",
    "\n",
    "cache.ResetKey(\"my_forest\")\n",
    "var forest = cache.Cache(\"my_forest\", func() * iforest.Forest {return isoForestTrain_Test(data,data,configuration.treeNum,configuration.subsamplesize,outlier)})\n",
    "\n",
    "///////////////////////\n",
    "\n",
    "\n",
    "type config struct{\n",
    "\ttreeNum int\n",
    "\tsubsamplesize int\n",
    "}\n",
    "\n",
    "func CrossValidation(data map[int][][]float64,treenummax int,subsamplmax int,anomaly float64) *config{\n",
    "\n",
    "\tmeanF1Arr := make([]float64,0)\n",
    "\tconfigArr := make([]config,0)\n",
    "\ttreenumStep := 10\n",
    "\n",
    "\tfor tr_n :=10 ;tr_n <=treenummax; tr_n+= treenumStep{\n",
    "\t\tfor sss := 50; sss<=subsamplmax; sss+= 50{\n",
    "\t\t\tvar conf *config\n",
    "\t\t\tfmt.Println(\"Tree number = \",tr_n)\n",
    "\t\t\tfmt.Println(\"Subsamplingsize = \",sss)\n",
    "\t\t\t//Acc_arr:=make([]float64,0)\n",
    "\t\t\tF1_arr:=make([]float64,0)\n",
    "\t\t\tfor s := range StratifiedKFold(5,data){\n",
    "\t\t\t\t\tforest:=isoForestTrain_Test(s.TrainData, s.ValidateData,tr_n,sss,anomaly)\n",
    "\t\t\t\t\t//Acc_arr = append(Acc_arr,AccuracyScore(forest.Labels,s.LabelData))\n",
    "\t\t\t\t\tF1_arr = append(F1_arr,F1Score(forest.Labels,s.LabelData))\n",
    "\t\t\t\t}\n",
    "\t\t\t\t\t\n",
    "\t\t\tmean_f1:= Mean(F1_arr)\n",
    "\t\t\tfmt.Println(\"Configuration Mean F1 Score is \",mean_f1)\n",
    "\t\t    meanF1Arr = append(meanF1Arr,mean_f1)\n",
    "\n",
    "\t\t    conf = &config{\n",
    "\t\t\t\ttreeNum:tr_n,\n",
    "\t\t\t\tsubsamplesize:sss,\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tconfigArr = append(configArr,*conf)\n",
    "\t\t}\n",
    "\t\tif tr_n == 100{\n",
    "\t\t\ttreenumStep = 100\n",
    "\t\t}else if tr_n == 1000{\n",
    "\t\t\ttreenumStep = 500\n",
    "\t\t}\n",
    "\t}\n",
    "\tmaxIndex := findMaxIndex(meanF1Arr)\n",
    "\tbestConfig := configArr[maxIndex]\n",
    "\treturn &bestConfig\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%\n",
    "i := 1\n",
    "\t\n",
    "treenummax := 2000\n",
    "subsamplmax := 350\n",
    "treenumStep := 10\n",
    "\tfor s := 0 ;s < 5; s++{\t\n",
    "\t\t\n",
    "\t\tfmt.Println(\"Entering Iteration num \",i)\n",
    "\t\tfor tr_n :=10 ;tr_n <=treenummax; tr_n+= treenumStep{\n",
    "\t\t\tfor sss := 50; sss<=subsamplmax; sss+= 50{\n",
    "\t\t\t\tfmt.Println(\"tree number\", tr_n)\n",
    "\t\t\t\tfmt.Println(\"subsam\",sss)\n",
    "\t\t\t}\n",
    "\t\t\tif tr_n == 100{\n",
    "\t\t\t\ttreenumStep = 100\n",
    "\t\t\t}else if tr_n == 1000{\n",
    "\t\t\t\ttreenumStep = 500\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\ti++\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.175657275024252\n",
      "Predict Accuracy is... 0.9235719617859809\n",
      "Predict F1 is... 0.7137825183717799\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "data:=loadData(\"dataset.csv\")\n",
    "labels:=LoadLabels(\"labels.csv\")\n",
    "\n",
    "forestt := isoForestTrain_Test(data,data,90,150,0.07193103596551799)\n",
    "predict_labels := forestt.Labels\n",
    "fmt.Println(\"Predict Accuracy is...\",AccuracyScore(predict_labels,labels))\n",
    "fmt.Println(\"Predict F1 is...\",F1Score(predict_labels,labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.21.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
