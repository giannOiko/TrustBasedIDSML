{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import KitNET as kit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../X_train.pkl\" , \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"../y_train.pkl\" , \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"../X_test.pkl\" , \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"../y_test.pkl\" , \"rb\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kitsune gets trained on a predefined number of samples which he takes as benign, then executes on the rest, so i have to make an input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get only benign from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train.copy()\n",
    "\n",
    "train_df['label'] = y_train\n",
    "train_one_class_df = train_df[train_df['label'] == 1 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = X_test.copy()\n",
    "\n",
    "test_df['label'] = y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_class_df_sort = train_one_class_df.sort_index()\n",
    "test_df_sort = test_df.sort_index()\n",
    "y_test_sort = test_df_sort['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and concat both. dataset consists of 35000 benign only training and 50000 mixed testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 1    35500\n",
       "-1    14500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_sort.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing comes first with benign and then only malicious treating dataset like the original kitsune example, thats why the sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kitsune_df = pd.concat([train_one_class_df_sort,test_df_sort])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.99938</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>1.085560e-04</td>\n",
       "      <td>1.99972</td>\n",
       "      <td>113.9980</td>\n",
       "      <td>1.116200e-01</td>\n",
       "      <td>2.09528</td>\n",
       "      <td>111.9170</td>\n",
       "      <td>106.230000</td>\n",
       "      <td>5.11994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.86453</td>\n",
       "      <td>102.8030</td>\n",
       "      <td>1.825060e+02</td>\n",
       "      <td>2.48821</td>\n",
       "      <td>103.0490</td>\n",
       "      <td>1.628830e+02</td>\n",
       "      <td>7.14736</td>\n",
       "      <td>102.3650</td>\n",
       "      <td>159.065000</td>\n",
       "      <td>78.60640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>161.2200</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.85173</td>\n",
       "      <td>106.7290</td>\n",
       "      <td>1.470560e+02</td>\n",
       "      <td>3.47795</td>\n",
       "      <td>106.1980</td>\n",
       "      <td>1.406160e+02</td>\n",
       "      <td>8.13752</td>\n",
       "      <td>103.7950</td>\n",
       "      <td>154.109000</td>\n",
       "      <td>79.59550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>161.2200</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.89126</td>\n",
       "      <td>90.5670</td>\n",
       "      <td>5.902230e+02</td>\n",
       "      <td>3.71838</td>\n",
       "      <td>93.7737</td>\n",
       "      <td>5.224110e+02</td>\n",
       "      <td>8.49585</td>\n",
       "      <td>98.6401</td>\n",
       "      <td>335.154000</td>\n",
       "      <td>79.94450</td>\n",
       "      <td>...</td>\n",
       "      <td>9.094950e-13</td>\n",
       "      <td>-6.251840e-36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.95863</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>9.536740e-07</td>\n",
       "      <td>84.8528</td>\n",
       "      <td>1.286220e-12</td>\n",
       "      <td>2.484300e-29</td>\n",
       "      <td>2.731520e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.32915</td>\n",
       "      <td>75.1596</td>\n",
       "      <td>3.638940e+01</td>\n",
       "      <td>1.63052</td>\n",
       "      <td>77.7364</td>\n",
       "      <td>8.525630e+01</td>\n",
       "      <td>3.16704</td>\n",
       "      <td>85.4821</td>\n",
       "      <td>220.716000</td>\n",
       "      <td>27.68580</td>\n",
       "      <td>...</td>\n",
       "      <td>2.254730e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.93182</td>\n",
       "      <td>82.8717</td>\n",
       "      <td>1.551040e+01</td>\n",
       "      <td>133.7640</td>\n",
       "      <td>2.405720e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>7.91606</td>\n",
       "      <td>82.2990</td>\n",
       "      <td>2.302610e+00</td>\n",
       "      <td>10.74610</td>\n",
       "      <td>82.3585</td>\n",
       "      <td>2.739510e+00</td>\n",
       "      <td>22.64480</td>\n",
       "      <td>82.2661</td>\n",
       "      <td>2.227450</td>\n",
       "      <td>74.76050</td>\n",
       "      <td>...</td>\n",
       "      <td>2.728480e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.22340</td>\n",
       "      <td>82.0000</td>\n",
       "      <td>1.348700e-06</td>\n",
       "      <td>82.0000</td>\n",
       "      <td>1.818990e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>1.86017</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>1.818990e-12</td>\n",
       "      <td>1.91359</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>9.094950e-13</td>\n",
       "      <td>1.97052</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>6.68654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99970</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>9.536740e-07</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>9.094950e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>110.0000</td>\n",
       "      <td>2.218020e-07</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>110.0000</td>\n",
       "      <td>1.293440e-03</td>\n",
       "      <td>1.01315</td>\n",
       "      <td>109.6890</td>\n",
       "      <td>7.377100</td>\n",
       "      <td>2.54652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384710e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.49450</td>\n",
       "      <td>90.1841</td>\n",
       "      <td>9.105580e+00</td>\n",
       "      <td>90.1841</td>\n",
       "      <td>8.291160e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2.00582</td>\n",
       "      <td>60.0655</td>\n",
       "      <td>1.435830e+00</td>\n",
       "      <td>2.11972</td>\n",
       "      <td>61.1742</td>\n",
       "      <td>2.445450e+01</td>\n",
       "      <td>6.61853</td>\n",
       "      <td>71.7619</td>\n",
       "      <td>120.420000</td>\n",
       "      <td>108.64700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2.40571</td>\n",
       "      <td>89.9386</td>\n",
       "      <td>8.925280e+01</td>\n",
       "      <td>2.90284</td>\n",
       "      <td>91.9687</td>\n",
       "      <td>1.589370e+02</td>\n",
       "      <td>7.04075</td>\n",
       "      <td>94.2802</td>\n",
       "      <td>367.820000</td>\n",
       "      <td>73.99090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85500 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1             2         3         4             5    \\\n",
       "6      1.99938  114.0000  1.085560e-04   1.99972  113.9980  1.116200e-01   \n",
       "7      1.86453  102.8030  1.825060e+02   2.48821  103.0490  1.628830e+02   \n",
       "8      2.85173  106.7290  1.470560e+02   3.47795  106.1980  1.406160e+02   \n",
       "12     2.89126   90.5670  5.902230e+02   3.71838   93.7737  5.224110e+02   \n",
       "20     1.32915   75.1596  3.638940e+01   1.63052   77.7364  8.525630e+01   \n",
       "...        ...       ...           ...       ...       ...           ...   \n",
       "99989  7.91606   82.2990  2.302610e+00  10.74610   82.3585  2.739510e+00   \n",
       "99993  1.86017   88.0000  1.818990e-12   1.91359   88.0000  9.094950e-13   \n",
       "99994  1.00000  110.0000  2.218020e-07   1.00000  110.0000  1.293440e-03   \n",
       "99996  2.00582   60.0655  1.435830e+00   2.11972   61.1742  2.445450e+01   \n",
       "99998  2.40571   89.9386  8.925280e+01   2.90284   91.9687  1.589370e+02   \n",
       "\n",
       "            6         7           8          9    ...           105  \\\n",
       "6       2.09528  111.9170  106.230000    5.11994  ...  0.000000e+00   \n",
       "7       7.14736  102.3650  159.065000   78.60640  ...  0.000000e+00   \n",
       "8       8.13752  103.7950  154.109000   79.59550  ...  0.000000e+00   \n",
       "12      8.49585   98.6401  335.154000   79.94450  ...  9.094950e-13   \n",
       "20      3.16704   85.4821  220.716000   27.68580  ...  2.254730e+02   \n",
       "...         ...       ...         ...        ...  ...           ...   \n",
       "99989  22.64480   82.2661    2.227450   74.76050  ...  2.728480e-12   \n",
       "99993   1.97052   88.0000    0.000024    6.68654  ...  0.000000e+00   \n",
       "99994   1.01315  109.6890    7.377100    2.54652  ...  1.384710e+02   \n",
       "99996   6.61853   71.7619  120.420000  108.64700  ...  0.000000e+00   \n",
       "99998   7.04075   94.2802  367.820000   73.99090  ...  0.000000e+00   \n",
       "\n",
       "                106  107       108       109           110       111  \\\n",
       "6      0.000000e+00  0.0   1.00000  114.0000  0.000000e+00  114.0000   \n",
       "7      0.000000e+00  0.0   1.00000  114.0000  0.000000e+00  161.2200   \n",
       "8      0.000000e+00  0.0   1.00000  114.0000  0.000000e+00  161.2200   \n",
       "12    -6.251840e-36  0.0   7.95863   60.0000  9.536740e-07   84.8528   \n",
       "20     0.000000e+00  0.0   2.93182   82.8717  1.551040e+01  133.7640   \n",
       "...             ...  ...       ...       ...           ...       ...   \n",
       "99989  0.000000e+00  0.0  58.22340   82.0000  1.348700e-06   82.0000   \n",
       "99993  0.000000e+00  0.0   1.99970   88.0000  9.536740e-07   88.0000   \n",
       "99994  0.000000e+00  0.0  21.49450   90.1841  9.105580e+00   90.1841   \n",
       "99996  0.000000e+00  0.0   1.00000   60.0000  0.000000e+00   60.0000   \n",
       "99998  0.000000e+00  0.0   1.00000   86.0000  0.000000e+00   86.0000   \n",
       "\n",
       "                112           113           114  \n",
       "6      0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "7      0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "8      0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "12     1.286220e-12  2.484300e-29  2.731520e-17  \n",
       "20     2.405720e+02  0.000000e+00  0.000000e+00  \n",
       "...             ...           ...           ...  \n",
       "99989  1.818990e-12  0.000000e+00  0.000000e+00  \n",
       "99993  9.094950e-13  0.000000e+00  0.000000e+00  \n",
       "99994  8.291160e+01  0.000000e+00  0.000000e+00  \n",
       "99996  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "99998  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "\n",
       "[85500 rows x 115 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kitsune = Kitsune_df.drop('label',axis=1)\n",
    "X_kitsune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Mapper: train-mode, Anomaly-Detector: off-mode\n",
      "Running KitNET:\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "The Feature-Mapper found a mapping: 115 features to 19 autoencoders.\n",
      "Feature-Mapper: execute-mode, Anomaly-Detector: train-mode\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "Feature-Mapper: execute-mode, Anomaly-Detector: exeute-mode\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "Complete. Time elapsed: 1019.2790184020996\n"
     ]
    }
   ],
   "source": [
    "# KitNET params:\n",
    "maxAE = 10 #maximum size for any autoencoder in the ensemble layer\n",
    "FMgrace = 5000 #the number of instances taken to learn the feature mapping (the ensemble's architecture)\n",
    "ADgrace = 30500 #the number of instances used to train the anomaly detector (ensemble itself)\n",
    "\n",
    "# Build KitNET\n",
    "K = kit.KitNET(X_kitsune.shape[1],maxAE,FMgrace,ADgrace)\n",
    "RMSEs = np.zeros(X_kitsune.shape[0]) # a place to save the scores\n",
    "\n",
    "print(\"Running KitNET:\")\n",
    "start = time.time()\n",
    "# Here we process (train/execute) each individual observation.\n",
    "# In this way, X is essentially a stream, and each observation is discarded after performing process() method.\n",
    "for i in range(X_kitsune.shape[0]):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    RMSEs[i] = K.process(X_kitsune.iloc[i]) #will train during the grace periods, then execute on all the rest.\n",
    "stop = time.time()\n",
    "print(\"Complete. Time elapsed: \"+ str(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we demonstrate how one can fit the RMSE scores to a log-normal distribution (useful for finding/setting a cutoff threshold \\phi)\n",
    "from scipy.stats import norm\n",
    "benignSample = np.log(RMSEs[FMgrace+ADgrace+1:71000])\n",
    "logProbs = norm.logsf(np.log(RMSEs), np.mean(benignSample), np.std(benignSample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goikon/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.7534704706387907\n",
      "best score is 0.792198308936773\n",
      "best score is 0.8349139795252835\n",
      "best score is 0.858718118964745\n",
      "best score is 0.8863425822988168\n",
      "best score is 0.9057551723975802\n",
      "best score is 0.9193503158469769\n",
      "best score is 0.9302881588136841\n",
      "best score is 0.9366612281389098\n",
      "best score is 0.9416276170348051\n",
      "best score is 0.9457839033528682\n",
      "best score is 0.948435090373905\n",
      "best score is 0.9500207358351997\n",
      "best score is 0.9511180722650054\n",
      "best score is 0.9523581552874748\n",
      "best score is 0.9531822742468207\n",
      "best score is 0.9540705372166349\n",
      "best score is 0.9547186509743365\n",
      "best score is 0.9555896192009193\n",
      "best score is 0.9568918066198911\n",
      "best score is 0.9583588964328197\n",
      "best score is 0.9596634106915153\n",
      "best score is 0.9609369734357348\n",
      "best score is 0.9616366998210553\n",
      "best score is 0.9623091580996906\n",
      "best score is 0.962631985895245\n",
      "best score is 0.96303187108805\n",
      "best score is 0.9635085454514041\n",
      "best score is 0.9642158996146464\n",
      "best score is 0.9645112734560066\n",
      "best score is 0.9646909429343307\n",
      "best score is 0.9648192212735781\n",
      "best score is 0.9650756357321117\n",
      "best score is 0.9651397097649077\n",
      "best score is 0.9651781485121309\n",
      "best score is 0.9652293935608564\n",
      "best score is 0.9652457588065834\n",
      "best score is 0.9652981705869351\n",
      "best score is 0.9653749971964144\n",
      "best score is 0.9655053513697162\n",
      "best score is 0.9655938193868256\n",
      "best f1 score = 0.9655938193868256\n",
      "precision score = 0.968222979270038\n",
      "recall score = 0.9670292397660819\n",
      "best threshold score = -15.344464809387333\n"
     ]
    }
   ],
   "source": [
    "# Calculate and plot F1 scores\n",
    "thresholds = np.linspace(min(logProbs), max(logProbs), num=50)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "labels = np.zeros(85500, dtype=int)\n",
    "\n",
    "# Set the last part of the array to ones\n",
    "labels[71000:] = 1\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "for threshold in thresholds:\n",
    "     \n",
    "    predictions = (logProbs < threshold).astype(int)\n",
    "    f11_score = f1_score(y_true = labels, y_pred = predictions,average = 'weighted')\n",
    "    f1_scores.append(f11_score)\n",
    "    precision_scores.append(precision_score(y_true = labels, y_pred = predictions,pos_label = 1,average = 'weighted'))\n",
    "    recall_scores.append(recall_score(y_true = labels, y_pred = predictions,pos_label = 1,average = 'weighted'))\n",
    "    if f11_score > best_score:\n",
    "        best_score = f11_score\n",
    "        print(\"best score is \"+ str(best_score))\n",
    "        best_precision = precision_scores[-1]\n",
    "        best_recall = recall_scores[-1]\n",
    "        best_threshold = threshold\n",
    "    \n",
    "\n",
    "print(\"best f1 score = \"+ str(best_score))\n",
    "print(\"precision score = \"+ str(best_precision))\n",
    "print(\"recall score = \"+ str(best_recall))\n",
    "print(\"best threshold score = \"+ str(best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okaay, here's the score for the Kitsune 0.9655 F1 Score Impressive for outlier detection, better than OCSVM (0.9377) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
